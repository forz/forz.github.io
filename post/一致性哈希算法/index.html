<!DOCTYPE html>
<html lang="zh-cn">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>一致性哈希算法 - Forz</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<meta name="author" content="Forz" /><meta name="description" content="Redis集群的使用 我们在使用Redis的时候，为了保证Redis的高可用，提高Redis的读写性能，最简单的方式我们会做主从复制，组成Ma" /><meta name="keywords" content="Hugo, theme, even" />






<meta name="generator" content="Hugo 0.55.6 with theme even" />


<link rel="canonical" href="http://localhost:1313/post/%E4%B8%80%E8%87%B4%E6%80%A7%E5%93%88%E5%B8%8C%E7%AE%97%E6%B3%95/" />
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">


<link href="/dist/even.c2a46f00.min.css" rel="stylesheet">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.css" integrity="sha256-7TyXnr2YU040zfSP+rEcz29ggW4j56/ujTPwjMzyqFY=" crossorigin="anonymous">


<meta property="og:title" content="一致性哈希算法" />
<meta property="og:description" content="Redis集群的使用 我们在使用Redis的时候，为了保证Redis的高可用，提高Redis的读写性能，最简单的方式我们会做主从复制，组成Ma" />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://localhost:1313/post/%E4%B8%80%E8%87%B4%E6%80%A7%E5%93%88%E5%B8%8C%E7%AE%97%E6%B3%95/" />
<meta property="article:published_time" content="2017-08-27T07:04:28&#43;00:00"/>
<meta property="article:modified_time" content="2017-08-27T07:04:28&#43;00:00"/>

<meta itemprop="name" content="一致性哈希算法">
<meta itemprop="description" content="Redis集群的使用 我们在使用Redis的时候，为了保证Redis的高可用，提高Redis的读写性能，最简单的方式我们会做主从复制，组成Ma">


<meta itemprop="datePublished" content="2017-08-27T07:04:28&#43;00:00" />
<meta itemprop="dateModified" content="2017-08-27T07:04:28&#43;00:00" />
<meta itemprop="wordCount" content="6977">



<meta itemprop="keywords" content="" />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="一致性哈希算法"/>
<meta name="twitter:description" content="Redis集群的使用 我们在使用Redis的时候，为了保证Redis的高可用，提高Redis的读写性能，最简单的方式我们会做主从复制，组成Ma"/>

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">Forz Blog</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/">
        <li class="mobile-menu-item">Home</li>
      </a><a href="/post/">
        <li class="mobile-menu-item">Archives</li>
      </a><a href="/tags/">
        <li class="mobile-menu-item">Tags</li>
      </a><a href="/categories/">
        <li class="mobile-menu-item">Categories</li>
      </a>
  </ul>
</nav>
  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="/" class="logo">Forz Blog</a>
</div>

<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="/">Home</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/post/">Archives</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/tags/">Tags</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/categories/">Categories</a>
      </li>
  </ul>
</nav>
    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title">一致性哈希算法</h1>

      <div class="post-meta">
        <span class="post-time"> 2017-08-27 </span>
        <div class="post-category">
            <a href="/categories/%E7%AE%97%E6%B3%95/"> 算法 </a>
            </div>
          <span class="more-meta"> 约 6977 字 </span>
          <span class="more-meta"> 预计阅读 14 分钟 </span>
        
      </div>
    </header>

    <div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">文章目录</h2>
  <div class="post-toc-content always-active">
    <nav id="TableOfContents">
<ul>
<li><a href="#redis集群的使用">Redis集群的使用</a></li>
<li><a href="#为redis集群使用hash">为Redis集群使用Hash</a></li>
<li><a href="#使用hash的问题">使用Hash的问题</a></li>
<li><a href="#哈希算法的好坏定义">哈希算法的好坏定义</a></li>
<li><a href="#一致性hash算法的神秘面纱">一致性Hash算法的神秘面纱</a></li>
<li><a href="#一致性hash算法的容错性和可扩展性">一致性Hash算法的容错性和可扩展性</a></li>
<li><a href="#hash环的数据倾斜问题">Hash环的数据倾斜问题</a></li>
<li><a href="#热点问题">热点问题</a>
<ul>
<li><a href="#维护多个一致性hash环">维护多个一致性HASH环</a></li>
<li><a href="#固定路由">固定路由</a></li>
<li><a href="#均衡权重">均衡权重</a></li>
</ul></li>
<li><a href="#扩散问题">扩散问题</a></li>
<li><a href="#jump-consistent-hash">Jump consistent hash</a></li>
</ul>
</nav>
  </div>
</div>
    <div class="post-content">
      

<h1 id="redis集群的使用">Redis集群的使用</h1>

<p>我们在使用Redis的时候，为了保证Redis的高可用，提高Redis的读写性能，最简单的方式我们会做主从复制，组成Master-Master或者Master-Slave的形式，或者搭建Redis集群，进行数据的读写分离，类似于数据库的主从复制和读写分离。如下所示：</p>

<p><img src="https://blog-1257321977.cos.ap-beijing.myqcloud.com/20190928140045.png" alt="" /></p>

<p>同样类似于数据库，当单表数据大于500W的时候需要对其进行分库分表，当数据量很大的时候（标准可能不一样，要看Redis服务器容量）我们同样可以对Redis进行类似的操作，就是分库分表。</p>

<p>假设，我们有一个社交网站，需要使用Redis存储图片资源，存储的格式为键值对，key值为图片名称，value为该图片所在文件服务器的路径，我们需要根据文件名查找该文件所在文件服务器上的路径，数据量大概有2000W左右，按照我们约定的规则进行分库，规则就是随机分配，我们可以部署8台缓存服务器，每台服务器大概含有500W条数据，并且进行主从复制，示意图如下：</p>

<p><img src="https://blog-1257321977.cos.ap-beijing.myqcloud.com/20190928140652.png" alt="" /></p>

<p>由于规则是随机的，所有我们的一条数据都有可能存储在任何一组Redis中，例如上图我们用户查找一张名称为”a.png”的图片，由于规则是随机的，我们不确定具体是在哪一个Redis服务器上的，因此我们需要进行1、2、3、4，4次查询才能够查询到（也就是遍历了所有的Redis服务器），这显然不是我们想要的结果，有了解过的小伙伴可能会想到，随机的规则不行，可以使用类似于数据库中的分库分表规则：按照Hash值、取模、按照类别、按照某一个字段值等等常见的规则就可以出来了！好，按照我们的主题，我们就使用Hash的方式。</p>

<h1 id="为redis集群使用hash">为Redis集群使用Hash</h1>

<p>可想而知，如果我们使用Hash的方式，每一张图片在进行分库的时候都可以定位到特定的服务器，示意图如下：</p>

<p><img src="https://blog-1257321977.cos.ap-beijing.myqcloud.com/20190928140809.png" alt="" /></p>

<p>上图中，假设我们查找的是”a.png”，由于有4台服务器（排除从库），因此公式为hash(a.png) % 4 = 2 ，可知定位到了第2号服务器，这样的话就不会遍历所有的服务器，大大提升了性能！</p>

<h1 id="使用hash的问题">使用Hash的问题</h1>

<p>上述的方式虽然提升了性能，我们不再需要对整个Redis服务器进行遍历！但是，使用上述Hash算法进行缓存时，会出现一些缺陷，主要体现在服务器数量变动的时候，所有缓存的位置都要发生改变！</p>

<p>试想一下，如果4台缓存服务器已经不能满足我们的缓存需求，那么我们应该怎么做呢？很简单，多增加几台缓存服务器不就行了！假设：我们增加了一台缓存服务器，那么缓存服务器的数量就由4台变成了5台。那么原本hash(a.png) % 4 = 2 的公式就变成了hash(a.png) % 5 = ？ ， 可想而知这个结果肯定不是2的，这种情况带来的结果就是当服务器数量变动时，所有缓存的位置都要发生改变！换句话说，当服务器数量发生改变时，所有缓存在一定时间内是失效的，当应用无法从缓存中获取数据时，则会向后端数据库请求数据</p>

<p>同样的，假设4台缓存中突然有一台缓存服务器出现了故障，无法进行缓存，那么我们则需要将故障机器移除，但是如果移除了一台缓存服务器，那么缓存服务器数量从4台变为3台，也是会出现上述的问题！</p>

<p>所以，我们应该想办法不让这种情况发生，但是由于上述Hash算法本身的缘故，使用取模法进行缓存时，这种情况是无法避免的，为了解决这些问题，Hash一致性算法（一致性Hash算法）诞生了！</p>

<h1 id="哈希算法的好坏定义">哈希算法的好坏定义</h1>

<p>一致性hash算法提出了在动态变化的Cache环境中，判定哈希算法好坏的四个定义：</p>

<ol>
<li><p>平衡性(Balance)：平衡性是指哈希的结果能够尽可能分布到所有的缓冲中去，这样可以使得所有的缓冲空间都得到利用。很多哈希算法都能够满足这一条件。</p></li>

<li><p>单调性(Monotonicity)：单调性是指如果已经有一些内容通过哈希分派到了相应的缓冲中，又有新的缓冲加入到系统中。哈希的结果应能够保证原有已分配的内容可以被映射到原有的或者新的缓冲中去，而不会被映射到旧的缓冲集合中的其他缓冲区。</p></li>

<li><p>分散性(Spread)：在分布式环境中，终端有可能看不到所有的缓冲，而是只能看到其中的一部分。当终端希望通过哈希过程将内容映射到缓冲上时，由于不同终端所见的缓冲范围有可能不同，从而导致哈希的结果不一致，最终的结果是相同的内容被不同的终端映射到不同的缓冲区中。这种情况显然是应该避免的，因为它导致相同内容被存储到不同缓冲中去，降低了系统存储的效率。分散性的定义就是上述情况发生的严重程度。好的哈希算法应能够尽量避免不一致的情况发生，也就是尽量降低分散性。</p></li>

<li><p>负载(Load)：负载问题实际上是从另一个角度看待分散性问题。既然不同的终端可能将相同的内容映射到不同的缓冲区中，那么对于一个特定的缓冲区而言，也可能被不同的用户映射为不同的内容。与分散性一样，这种情况也是应当避免的，因此好的哈希算法应能够尽量降低缓冲的负荷。</p></li>
</ol>

<h1 id="一致性hash算法的神秘面纱">一致性Hash算法的神秘面纱</h1>

<p>一致性Hash算法也是使用取模的方法，只是，刚才描述的取模法是对服务器的数量进行取模，而一致性Hash算法是对$2^{32}$取模，什么意思呢？简单来说，一致性Hash算法将整个哈希值空间组织成一个虚拟的圆环，如假设某哈希函数H的值空间为0~$2^{32}$-1（即哈希值是一个32位无符号整形），整个哈希环如下：</p>

<p><img src="https://blog-1257321977.cos.ap-beijing.myqcloud.com/20190928141309.png" alt="" /></p>

<p>整个空间按顺时针方向组织，圆环的正上方的点代表0，0点右侧的第一个点代表1，以此类推，2、3、4、5、6……直到$2^{32}$-1，也就是说0点左侧的第一个点代表$2^{32}$-1， 0和$2^{32}$-1在零点中方向重合，我们把这个由$2^{32}$个点组成的圆环称为Hash环。</p>

<p>下一步将各个服务器使用Hash进行一个哈希，具体可以选择服务器的IP或主机名作为关键字进行哈希，这样每台机器就能确定其在哈希环上的位置，这里假设将上文中四台服务器使用IP地址哈希后在环空间的位置如下：</p>

<p><img src="https://blog-1257321977.cos.ap-beijing.myqcloud.com/20190928143923.png" alt="" /></p>

<p>接下来使用如下算法定位数据访问到相应服务器：将数据key使用相同的函数Hash计算出哈希值，并确定此数据在环上的位置，从此位置沿环顺时针“行走”，第一台遇到的服务器就是其应该定位到的服务器！</p>

<p>例如我们有Object A、Object B、Object C、Object D四个数据对象，经过哈希计算后，在环空间上的位置如下：</p>

<p><img src="https://blog-1257321977.cos.ap-beijing.myqcloud.com/20190928153429.png" alt="" /></p>

<p>根据一致性Hash算法，数据A会被定为到Node A上，B被定为到Node B上，C被定为到Node C上，D被定为到Node D上。</p>

<h1 id="一致性hash算法的容错性和可扩展性">一致性Hash算法的容错性和可扩展性</h1>

<p>现假设Node C不幸宕机，可以看到此时对象A、B、D不会受到影响，只有C对象被重定位到Node D。一般的，在一致性Hash算法中，如果一台服务器不可用，则受影响的数据仅仅是此服务器到其环空间中前一台服务器（即沿着逆时针方向行走遇到的第一台服务器）之间数据，其它不会受到影响，如下所示：</p>

<p><img src="https://blog-1257321977.cos.ap-beijing.myqcloud.com/20190928153511.png" alt="" /></p>

<p>下面考虑另外一种情况，如果在系统中增加一台服务器Node X，如下图所示：</p>

<p><img src="https://blog-1257321977.cos.ap-beijing.myqcloud.com/20190928153601.png" alt="" /></p>

<p>此时对象Object A、B、D不受影响，只有对象C需要重定位到新的Node X ！一般的，在一致性Hash算法中，如果增加一台服务器，则受影响的数据仅仅是新服务器到其环空间中前一台服务器（即沿着逆时针方向行走遇到的第一台服务器）之间数据，其它数据也不会受到影响。</p>

<p>综上所述，一致性Hash算法对于节点的增减都只需重定位环空间中的一小部分数据，具有较好的容错性和可扩展性。</p>

<h1 id="hash环的数据倾斜问题">Hash环的数据倾斜问题</h1>

<p>一致性Hash算法在服务节点太少时，容易因为节点分部不均匀而造成数据倾斜（被缓存的对象大部分集中缓存在某一台服务器上）问题，例如系统中只有两台服务器，其环分布如下：</p>

<p><img src="https://blog-1257321977.cos.ap-beijing.myqcloud.com/20190928153720.png" alt="" /></p>

<p>此时必然造成大量数据集中到Node A上，而只有极少量会定位到Node B上。为了解决这种数据倾斜问题，一致性Hash算法引入了虚拟节点机制，即对每一个服务节点计算多个哈希，每个计算结果位置都放置一个此服务节点，称为虚拟节点。具体做法可以在服务器IP或主机名的后面增加编号来实现。</p>

<p>例如上面的情况，可以为每台服务器计算三个虚拟节点，于是可以分别计算 “Node A#1”、“Node A#2”、“Node A#3”、“Node B#1”、“Node B#2”、“Node B#3”的哈希值，于是形成六个虚拟节点：</p>

<p><img src="https://blog-1257321977.cos.ap-beijing.myqcloud.com/20190928154010.png" alt="" /></p>

<p>同时数据定位算法不变，只是多了一步虚拟节点到实际节点的映射，例如定位到“Node A#1”、“Node A#2”、“Node A#3”三个虚拟节点的数据均定位到Node A上。这样就解决了服务节点少时数据倾斜的问题。在实际应用中，通常将虚拟节点数设置为32甚至更大，因此即使很少的服务节点也能做到相对均匀的数据分布。</p>

<h1 id="热点问题">热点问题</h1>

<p>有时候，我们已经将一致性HASH的虚拟节点调至最大了（假设有上限），发现流量依旧不均衡，甚至部分节点CPU跑满。 这时候甚至扩容都无法解决问题。</p>

<p>这种部分节点的流量总是比其他机器的流量高的问题，称为热KEY问题。这里面原因是多方面的，有可能确实是概率因素，但更多的是单KEY流量太高。此时我们无论怎么扩容或者增大虚拟节点个数都是无效的。因为一个KEY只会路由到一个机器，而这个KEY的量那台机器支持不住，那只能想其他办法了。</p>

<p>面对热KEY问题，常见的方案有三个</p>

<h2 id="维护多个一致性hash环">维护多个一致性HASH环</h2>

<p>第一个方案是维护多个一致性HASH环。</p>

<p>可以想象，目前只有一个一致性HAHS环，一个机器负载太高，增加节点无法解决问题。那增加一个一模一样的一致性HASH环，流量即可导走一半，这样热点问题就可以解决了。还有热点？再增加一致性HASH环。</p>

<p><img src="https://blog-1257321977.cos.ap-beijing.myqcloud.com/20190928163044.png" alt="" /></p>

<p>这种一致性HASH环，我们内部称为小set。小set是一个一致性HASH环，能支持指定指标流量的最小单位。当流量上涨超过指定指标时，我们就增加一个这样的最小单位。</p>

<p>具体实现上，对外一个路由表，路由层会有一定的策略将当前请求路由到其中一个小set。</p>

<p>这个策略对于所有小set是均等的，这样热key就会被均摊到不同的小set，从而解决热KEY问题。</p>

<p>这种架构是一种可无限扩容的设计。但是命中率不足需要加节点时，会发现成本很高，所有一致性HASH环都需要扩容，成本巨大。当然，这里面还有维护成本。</p>

<p>每一个小set都有自己的路由表，由于某些原因小set的机器还需要知道自己属于哪个大set时，配置表将更为复杂。扩容成本相当高。</p>

<h2 id="固定路由">固定路由</h2>

<p>第二个方案是一致性HASH环下的节点不再是机器，而是一个路由表，每个路由表下又有多台机器。</p>

<p>这个时候，热KEY就可以通过多台机器来均摊流量。</p>

<p>原型: 请求的key hash到一个数字, 然后这个数字直接对机器数取模来决定路由到某台机器上.</p>

<p>问题: 机器减少或增多, key与机器的关系会重映射, 瞬间命中率很低.</p>

<p>一致性hash的解决方案是对机器也进行hash, 这样key和机器都是一系列数字, 然后我们定义一个规则:每个请求的key属于环上顺时针方向的第一个机器, 也就是第一个大于key的机器.</p>

<p>再深入的看一致性hash这个方案, 其本质是它不是不取模了, 而是取模固定了, 比如是整数最大值.当取模因子固定后, 再定一个策略把机器与key关联上即可.</p>

<p>看到这里, 很容易得出结论: 解决这个问题的本质在于减少key与机器的重映射, 最常见的方案是取模因子固定.</p>

<p>既然这样, 我们取一个相当大的取模因子即可, 比如一个很大的质数 10007.然后定义一个区间来和机器关联上.</p>

<p><img src="https://blog-1257321977.cos.ap-beijing.myqcloud.com/20190928164911.png" alt="" /></p>

<p>这样我们也可以得到一个key与机器的映射关系, 而且某个区间负载比较高了,我们调整这个区间与机器的关系即可.</p>

<p>现在我们再来看看删除机器与增加机器的影响.增加机器时, 拆分某个区间, 拆除的新区间分给新机器. 只影响两个区间.删除机器时, 直接把这个区间挂在其他机器下接口. 也是只影响两个区间.</p>

<p><img src="https://blog-1257321977.cos.ap-beijing.myqcloud.com/20190928165048.png" alt="" /></p>

<p>但是我这个业务比较特殊: 请求有N个key, 经过映射请求将会扩散N倍, 流量也会翻一倍, 很多其他操作也被放大N倍,这样再扩散, 下层也撑不住了.</p>

<p>所以面临一个问题: 一个机器不能简单的当做一个节点了, 一个节点应该是一组机器, 然后我们需要固定的节点数,即对机器分组.</p>

<p>这个时候就需要维护N个节点与机器的关系了, 成本好高, 但是面对扩散问题, 只好选择维护成本高的固定节点这个方案了.</p>

<p><img src="https://blog-1257321977.cos.ap-beijing.myqcloud.com/20190928171646.png" alt="" /></p>

<p>这种设计其实和上面的小set设计很像。但是有一个天然优势：按需扩容。</p>

<p>由于只有一个HASH环，某个节点负载高了，对应的节点下面增加机器即可。节点的整体命中率降低了，增加一致性HASH节点即可。而命中率这一方面，小set是处于劣势的，因为所有小set都需要去扩容，成本太高。</p>

<p>当然，这种方法也面临着小set的管理问题。由于每个节点都是一个路由表，我们就需要维护很多路由表。如果这些路由表不能和管理系统结合，那将来扩容时，都会有很高的成本。</p>

<h2 id="均衡权重">均衡权重</h2>

<p>我们可以实现一种理想模型：自动调整一致性HASH的权重从而做到自动调节负载。</p>

<p>我们可以实现一个监控程序来监控每个节点的负载。当遇到部分节点负载过高时，就调小高负载节点的权重，调大低负载节点的权重，从而使得各机器的负载较为平均。降低热KEY机器的权重，也可以理解为降低虚拟节点的个数（其他的不变）。</p>

<p>这里只有一个问题：怎么判断节点的负载高低与权重的关系。</p>

<p>对于高并发服务，其实有三个基本指标：请求量、失败量、延时。我们可以通过这三个基本指标计算出一个权重来。</p>

<p>对应的关系是：与失败量负相关、与延时负相关、与请求量正相关。那可以写出一个简单的公式来：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><span class="lnt">1
</span></pre></td>
<td class="lntd">
<pre class="chroma">权重 = （请求量 - 失败量）/耗时</pre></td></tr></table>
</div>
</div>
<p>当然，这个公式只是基础模型，具体实现的时候可能会加一些系数或者 log 什么来使得负载更均衡。</p>

<p>另外，使用动态负载的时候，还需要考虑一个问题：抖动。</p>

<p>假设负载都是正常的，不能因为我们的算法导致某台机器的流量一会高一会低。这个抖动也势必会使命中率发生抖动，所以需要想办法避免。比如一段时间内只调整一次，或者权重忽略低位等等，方法很多。</p>

<h1 id="扩散问题">扩散问题</h1>

<p>大家使用一致性HASH的时候，可能都是只有一个路由KEY。但是对于批量请求的缓存服务，就涉及到一致性HASH扩散问题了。</p>

<p>比如我们的一个HASH环下有5个节点，业务一次请求批量拉取30个KEY，业务的请求是10W/s。此时我们该如何使用一致性HASH支持这个需求呢？</p>

<p>可能有些人没看出来问题是什么。</p>

<p>假设我们30个KEY分别一致性HASH向下拉取数据，那么对外路由层QPS是10W/S，对内缓存层QPS是300W/S。这么大的流量，网络操作等非业务操作就会消耗很多资源。所以批量请求需要在一致性HASH之后再聚合数据批量向下请求。</p>

<p>比如30个KEY平均的均摊在5个节点上，每个节点的6个KEY可以一次请求去拉数据，而不是6次请求。但是这样做对内的QPS也有50W/S，其实这个量也不小。此时，当负载过高时，我们增加一致性HASH节点无法解决问题。</p>

<p>为什么呢？</p>

<p>假设5台机器，对外QPS是10W/s，对内聚合请求QPS是50W/s（每个节点10W）。一致性HASH增加5个节点，这时对内的聚合请求QPS就是100W/S了，每台机器依旧是10W的QPS（单节点KEY量变少，负载会适当降低，但没有解决问题）。另外，这时候扩散更严重，意味着网络操作等额外操作会消耗更多的资源，</p>

<p>根据这个结论，我们可以反推出另一个结论：一致性HASH下应该有多少个节点？</p>

<p>答案是能够满足命中率指标的前提下（如储存下全量数据），节点数应该尽量的少。因为多余的节点不仅不能增加命中率，反而会因为扩散更严重而更消耗资源。</p>

<h1 id="jump-consistent-hash">Jump consistent hash</h1>

<p>对于分布式存储系统，当一个节点失效时，我们并不期望它被移除，而是使用备份节点替换它，或者将它恢复起来，因为我们不期望丢掉它上面的数据。对于这种情况(节点可以扩容，但是不会移除节点)，Google的 John Lamping, Eric Veach提供一个高效的几乎不占用持久内存的算法： Jump Consistent Hash。</p>

<p>Jump Consistent Hash算法的特点是：</p>

<ul>
<li>代码简单： 寥寥几行代码</li>
<li>不需要额外的内存映射：可是实时计算</li>
<li>快速</li>
<li>均匀：数据非常均匀地分布在各个节点</li>
</ul>

<p>golang版本实现如下:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code class="language-go" data-lang="go"><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-go" data-lang="go"><span class="kd">func</span> <span class="nf">JumpHash</span><span class="p">(</span><span class="nx">key</span> <span class="kt">uint64</span><span class="p">,</span> <span class="nx">buckets</span> <span class="kt">int</span><span class="p">)</span> <span class="kt">int</span> <span class="p">{</span>
	<span class="kd">var</span> <span class="nx">b</span><span class="p">,</span> <span class="nx">j</span> <span class="kt">int64</span>
	<span class="k">if</span> <span class="nx">buckets</span> <span class="o">&lt;=</span> <span class="mi">0</span> <span class="p">{</span>
		<span class="nx">buckets</span> <span class="p">=</span> <span class="mi">1</span>
	<span class="p">}</span>
	<span class="k">for</span> <span class="nx">j</span> <span class="p">&lt;</span> <span class="nb">int64</span><span class="p">(</span><span class="nx">buckets</span><span class="p">)</span> <span class="p">{</span>
		<span class="nx">b</span> <span class="p">=</span> <span class="nx">j</span>
		<span class="nx">key</span> <span class="p">=</span> <span class="nx">key</span><span class="o">*</span><span class="mi">2862933555777941757</span> <span class="o">+</span> <span class="mi">1</span>
		<span class="nx">j</span> <span class="p">=</span> <span class="nb">int64</span><span class="p">(</span><span class="nb">float64</span><span class="p">(</span><span class="nx">b</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="nb">float64</span><span class="p">(</span><span class="nb">int64</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">&lt;&lt;</span><span class="mi">31</span><span class="p">)</span> <span class="o">/</span> <span class="nb">float64</span><span class="p">((</span><span class="nx">key</span><span class="o">&gt;&gt;</span><span class="mi">33</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">)))</span>
	<span class="p">}</span>
	<span class="k">return</span> <span class="nb">int</span><span class="p">(</span><span class="nx">b</span><span class="p">)</span>
<span class="p">}</span></code></pre></td></tr></table>
</div>
</div>
<p>我们可以写段代码测试它，看看它的分布是否均匀，在新增加一个节点的时候，是否只移动了一部分的数据：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code class="language-go" data-lang="go"><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-go" data-lang="go"><span class="kn">package</span> <span class="nx">main</span>
<span class="kn">import</span> <span class="s">&#34;fmt&#34;</span>
<span class="kd">func</span> <span class="nf">main</span><span class="p">()</span> <span class="p">{</span>
	<span class="nx">buckets</span> <span class="o">:=</span> <span class="nb">make</span><span class="p">(</span><span class="kd">map</span><span class="p">[</span><span class="kt">int</span><span class="p">]</span><span class="kt">int</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
	<span class="nx">count</span> <span class="o">:=</span> <span class="mi">10</span>
	<span class="k">for</span> <span class="nx">i</span> <span class="o">:=</span> <span class="nb">uint64</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span> <span class="nx">i</span> <span class="p">&lt;</span> <span class="mi">120000</span><span class="p">;</span> <span class="nx">i</span><span class="o">++</span> <span class="p">{</span>
		<span class="nx">b</span> <span class="o">:=</span> <span class="nf">JumpHash</span><span class="p">(</span><span class="nx">i</span><span class="p">,</span> <span class="nx">count</span><span class="p">)</span>
		<span class="nx">buckets</span><span class="p">[</span><span class="nx">b</span><span class="p">]</span> <span class="p">=</span> <span class="nx">buckets</span><span class="p">[</span><span class="nx">b</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span>
	<span class="p">}</span>
	<span class="nx">fmt</span><span class="p">.</span><span class="nf">Printf</span><span class="p">(</span><span class="s">&#34;buckets: %v\n&#34;</span><span class="p">,</span> <span class="nx">buckets</span><span class="p">)</span>
	<span class="c1">//add two buckets
</span><span class="c1"></span>	<span class="nx">count</span> <span class="p">=</span> <span class="mi">12</span>
	<span class="k">for</span> <span class="nx">i</span> <span class="o">:=</span> <span class="nb">uint64</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span> <span class="nx">i</span> <span class="p">&lt;</span> <span class="mi">120000</span><span class="p">;</span> <span class="nx">i</span><span class="o">++</span> <span class="p">{</span>
		<span class="nx">oldBucket</span> <span class="o">:=</span> <span class="nf">JumpHash</span><span class="p">(</span><span class="nx">i</span><span class="p">,</span> <span class="nx">count</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span>
		<span class="nx">newBucket</span> <span class="o">:=</span> <span class="nf">JumpHash</span><span class="p">(</span><span class="nx">i</span><span class="p">,</span> <span class="nx">count</span><span class="p">)</span>
		<span class="c1">//如果对象需要移动到新的bucket中,则首先从原来的bucket删除，再移动
</span><span class="c1"></span>		<span class="k">if</span> <span class="nx">oldBucket</span> <span class="o">!=</span> <span class="nx">newBucket</span> <span class="p">{</span>
			<span class="nx">buckets</span><span class="p">[</span><span class="nx">oldBucket</span><span class="p">]</span> <span class="p">=</span> <span class="nx">buckets</span><span class="p">[</span><span class="nx">oldBucket</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span>
			<span class="nx">buckets</span><span class="p">[</span><span class="nx">newBucket</span><span class="p">]</span> <span class="p">=</span> <span class="nx">buckets</span><span class="p">[</span><span class="nx">newBucket</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span>
		<span class="p">}</span>
	<span class="p">}</span>
	<span class="nx">fmt</span><span class="p">.</span><span class="nf">Printf</span><span class="p">(</span><span class="s">&#34;buckets after add two servers: %v\n&#34;</span><span class="p">,</span> <span class="nx">buckets</span><span class="p">)</span>
<span class="p">}</span></code></pre></td></tr></table>
</div>
</div>
<p>因为Jump consistent hash算法不使用节点挂掉，如果你真的有这种需求，比如你要做一个缓存系统，你可以考虑使用ketama算法，或者对Jump consistent hash算法改造一下：节点挂掉时我们不移除节点，只是标记这个节点不可用。当选择节点时，如果选择的节点不可用，则再一次Hash，尝试选择另外一个节点，比如下面的算法将key加1再进行选择。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code class="language-go" data-lang="go"><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-go" data-lang="go"><span class="kd">func</span> <span class="nf">JumpHash</span><span class="p">(</span><span class="nx">key</span> <span class="kt">uint64</span><span class="p">,</span> <span class="nx">buckets</span> <span class="kt">int</span><span class="p">,</span> <span class="nx">checkAlive</span> <span class="kd">func</span><span class="p">(</span><span class="kt">int</span><span class="p">)</span> <span class="kt">bool</span><span class="p">)</span> <span class="kt">int</span> <span class="p">{</span>
	<span class="kd">var</span> <span class="nx">b</span><span class="p">,</span> <span class="nx">j</span> <span class="kt">int64</span> <span class="p">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span>
	<span class="k">if</span> <span class="nx">buckets</span> <span class="o">&lt;=</span> <span class="mi">0</span> <span class="p">{</span>
		<span class="nx">buckets</span> <span class="p">=</span> <span class="mi">1</span>
	<span class="p">}</span>
	<span class="k">for</span> <span class="nx">j</span> <span class="p">&lt;</span> <span class="nb">int64</span><span class="p">(</span><span class="nx">buckets</span><span class="p">)</span> <span class="p">{</span>
		<span class="nx">b</span> <span class="p">=</span> <span class="nx">j</span>
		<span class="nx">key</span> <span class="p">=</span> <span class="nx">key</span><span class="o">*</span><span class="mi">2862933555777941757</span> <span class="o">+</span> <span class="mi">1</span>
		<span class="nx">j</span> <span class="p">=</span> <span class="nb">int64</span><span class="p">(</span><span class="nb">float64</span><span class="p">(</span><span class="nx">b</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="nb">float64</span><span class="p">(</span><span class="nb">int64</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">&lt;&lt;</span><span class="mi">31</span><span class="p">)</span> <span class="o">/</span> <span class="nb">float64</span><span class="p">((</span><span class="nx">key</span><span class="o">&gt;&gt;</span><span class="mi">33</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">)))</span>
	<span class="p">}</span>
	<span class="k">if</span> <span class="nx">checkAlive</span> <span class="o">!=</span> <span class="kc">nil</span> <span class="o">&amp;&amp;</span> <span class="p">!</span><span class="nf">checkAlive</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="nx">b</span><span class="p">))</span> <span class="p">{</span>
		<span class="k">return</span> <span class="nf">JumpHash</span><span class="p">(</span><span class="nx">key</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="nx">buckets</span><span class="p">,</span> <span class="nx">checkAlive</span><span class="p">)</span> <span class="c1">//最好设置深度，避免key+1一直返回当掉的服务器
</span><span class="c1"></span>	<span class="p">}</span>
	<span class="k">return</span> <span class="nb">int</span><span class="p">(</span><span class="nx">b</span><span class="p">)</span>
<span class="p">}</span></code></pre></td></tr></table>
</div>
</div>
<p>上面的算法有一点问题，就是没有设定重试的测试，如果所有的节点都挂掉，则会进入死循环，所以最好设置一下重试次数(递归次数)，超过n次还没有选择到则返回失败。</p>

<p>参考:<br />
<a href="https://zhuanlan.zhihu.com/p/34985026">https://zhuanlan.zhihu.com/p/34985026</a><br />
<a href="https://mp.weixin.qq.com/s/yyqEwfEgEWYwWoalFLcuSw">https://mp.weixin.qq.com/s/yyqEwfEgEWYwWoalFLcuSw</a>
<a href="https://colobu.com/2016/03/22/jump-consistent-hash/">https://colobu.com/2016/03/22/jump-consistent-hash/</a></p>

    </div>

    <div class="post-copyright">
  <p class="copyright-item">
    <span class="item-title">文章作者</span>
    <span class="item-content">Forz</span>
  </p>
  <p class="copyright-item">
    <span class="item-title">上次更新</span>
    <span class="item-content">
        2017-08-27
        
    </span>
  </p>
  
  
</div>
<footer class="post-footer">
      
      <nav class="post-nav">
        <a class="prev" href="/post/%E4%B8%8D%E7%94%A8%E9%A2%9D%E5%A4%96%E5%8F%98%E9%87%8F%E4%BA%A4%E6%8D%A2%E4%B8%A4%E4%B8%AA%E6%95%B4%E6%95%B0%E7%9A%84%E5%80%BC/">
            <i class="iconfont icon-left"></i>
            <span class="prev-text nav-default">不用额外变量交换两个整数的值</span>
            <span class="prev-text nav-mobile">上一篇</span>
          </a>
        <a class="next" href="/post/%E6%89%BE%E5%88%B0%E8%A2%AB%E6%8C%87%E7%9A%84%E6%96%B0%E7%B1%BB%E5%9E%8B%E5%AD%97%E7%AC%A6/">
            <span class="next-text nav-default">找到被指的新类型字符</span>
            <span class="next-text nav-mobile">下一篇</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        

  

  

      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
      <a href="forzfuyao@email.com" class="iconfont icon-email" title="email"></a>
  <a href="http://localhost:1313/index.xml" type="application/rss+xml" class="iconfont icon-rss" title="rss"></a>
</div>

<div class="copyright">
  <span class="power-by">
    由 <a class="hexo-link" href="https://gohugo.io">Hugo</a> 强力驱动
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    主题 - 
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

  

  <span class="copyright-year">
    &copy; 
    2017 - 
    2019
    <span class="heart">
      <i class="iconfont icon-heart"></i>
    </span>
    <span class="author">Forz</span>
  </span>
</div>
    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js" integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.js" integrity="sha256-XVLffZaxoWfGUEbdzuLi7pwaUJv1cecsQJQqGLe7axY=" crossorigin="anonymous"></script>
<script type="text/javascript" src="/dist/even.26188efa.min.js"></script>
  <script type="text/javascript">
    window.MathJax = {
      tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
      showProcessingMessages: false,
      messageStyle: 'none'
    };
  </script>
  <script async src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"  integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script>








</body>
</html>
