<!DOCTYPE html>
<html lang="zh-cn" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Grpc在k8s集群中的负载均衡 | Forz Blog</title>
<meta name="keywords" content="k8s" />
<meta name="description" content="背景 很多刚刚接触 gRPC 的用户，通常会惊讶于 Kubernetes 默认提供的负载均衡对于 gRPC 来说无法实现开箱即用的效果。比如，将一个简单的基于 Node.js 实现的 gRPC 微服务部署在 Kubernetes 后">
<meta name="author" content="">
<link rel="canonical" href="/post/grpc%E5%9C%A8k8s%E9%9B%86%E7%BE%A4%E4%B8%AD%E7%9A%84%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/" />
<link crossorigin="anonymous" href="/assets/css/stylesheet.min.00d5d4fc479b1575183ee8d86b4fb372ba9d9b1904e96fa8e4c40ff7debe2b94.css" integrity="sha256-ANXU/EebFXUYPujYa0&#43;zcrqdmxkE6W&#43;o5MQP996&#43;K5Q=" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/assets/js/highlight.min.7680afc38aa6b15ddf158a4f3780b7b1f7dde7e91d26f073e6229bb7a0793c92.js" integrity="sha256-doCvw4qmsV3fFYpPN4C3sffd5&#43;kdJvBz5iKbt6B5PJI="
    onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="apple-touch-icon" href="/apple-touch-icon.png">
<link rel="mask-icon" href="/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<meta name="generator" content="Hugo 0.87.0" />
<meta property="og:title" content="Grpc在k8s集群中的负载均衡" />
<meta property="og:description" content="背景 很多刚刚接触 gRPC 的用户，通常会惊讶于 Kubernetes 默认提供的负载均衡对于 gRPC 来说无法实现开箱即用的效果。比如，将一个简单的基于 Node.js 实现的 gRPC 微服务部署在 Kubernetes 后" />
<meta property="og:type" content="article" />
<meta property="og:url" content="/post/grpc%E5%9C%A8k8s%E9%9B%86%E7%BE%A4%E4%B8%AD%E7%9A%84%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/" /><meta property="article:section" content="post" />
<meta property="article:published_time" content="2021-02-22T17:48:28&#43;00:00" />
<meta property="article:modified_time" content="2021-02-22T17:48:28&#43;00:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Grpc在k8s集群中的负载均衡"/>
<meta name="twitter:description" content="背景 很多刚刚接触 gRPC 的用户，通常会惊讶于 Kubernetes 默认提供的负载均衡对于 gRPC 来说无法实现开箱即用的效果。比如，将一个简单的基于 Node.js 实现的 gRPC 微服务部署在 Kubernetes 后"/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "/post/"
    }
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Grpc在k8s集群中的负载均衡",
      "item": "/post/grpc%E5%9C%A8k8s%E9%9B%86%E7%BE%A4%E4%B8%AD%E7%9A%84%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Grpc在k8s集群中的负载均衡",
  "name": "Grpc在k8s集群中的负载均衡",
  "description": "背景 很多刚刚接触 gRPC 的用户，通常会惊讶于 Kubernetes 默认提供的负载均衡对于 gRPC 来说无法实现开箱即用的效果。比如，将一个简单的基于 Node.js 实现的 gRPC 微服务部署在 Kubernetes 后",
  "keywords": [
    "k8s"
  ],
  "articleBody": "背景 很多刚刚接触 gRPC 的用户，通常会惊讶于 Kubernetes 默认提供的负载均衡对于 gRPC 来说无法实现开箱即用的效果。比如，将一个简单的基于 Node.js 实现的 gRPC 微服务部署在 Kubernetes 后，如下图所示：\n尽管选举服务显示存在多个 pod，但是从 Kubernetes 的 CPU 图表可以清晰的看出，只有一个 pod 能够接收到流量，处于工作状态。这是为什么？\nservice负载调度原理 在k8s的文档中阐述了kube-proxy的特点：\n1 2 3 4 5 6 7  The kube proxy: runs on each node #运行在每个节点 proxies UDP, TCP and SCTP #可以代理UDP、TCP、SCTP协议 does not understand HTTP #但是不能识别HTTP协议 provides load balancing #提供负载均衡 is just used to reach services #只用于到达服务   其中阐述了kube-proxy的iptbles代理，是不能支持应用层协议识别的。\n创建service后，kubernetes会在kube-proxy里面设置iptables相应规则，从api-server获取到后端pod的ip以及端口情况。生产相应转发规则\n当目标地址为service的地址10.97.211.12/32和目标端口为8000时，跳转到KUBE-SVC-EHPSUHUW2JIVMPQD链\n1 2 3  -A KUBE-SERVICES -d 10.97.211.12/32 -p tcp -m comment --comment \"default/backend:grpc cluster IP\" -m tcp --dport 8000 \\ -j KUBE-SVC-EHPSUHUW2JIVMPQD   链KUBE-SVC-EHPSUHUW2JIVMPQD为3条规则，副本数是3\n1 2 3  30.333%的几率去KUBE-SEP-MPFDKKCFY2PBGU4S链（pod1 的ip） -A KUBE-SVC-EHPSUHUW2JIVMPQD -m statistic --mode random --probability 0.33332999982 \\ -j KUBE-SEP-MPFDKKCFY2PBGU4S   1 2 3 4 5  50%的几率去KUBE-SEP-LMG22MVGXQA364F6链（pod2的ip地址） -A KUBE-SVC-EHPSUHUW2JIVMPQD -m statistic --mode random --probability 0.50000000000 \\ -j KUBE-SEP-LMG22MVGXQA364F6 其余的全部走KUBE-SEP-EX64MF3TTLO7J5EC链（pod3的ip地址） -A KUBE-SVC-EHPSUHUW2JIVMPQD -j KUBE-SEP-EX64MF3TTLO7J5EC   pod3的ip地址\n1 2  -A KUBE-SEP-EX64MF3TTLO7J5EC -s 10.80.167.226/32 -j KUBE-MARK-MASQ -A KUBE-SEP-EX64MF3TTLO7J5EC -p tcp -m tcp -j DNAT --to-destination 10.80.167.226:8000   pod1的ip地址\n1 2  -A KUBE-SEP-MPFDKKCFY2PBGU4S -s 10.80.128.247/32 -j KUBE-MARK-MASQ -A KUBE-SEP-MPFDKKCFY2PBGU4S -p tcp -m tcp -j DNAT --to-destination 10.80.128.247:8000   pod2的ip地址\n1 2  -A KUBE-SEP-LMG22MVGXQA364F6 -s 10.80.153.167/32 -j KUBE-MARK-MASQ -A KUBE-SEP-LMG22MVGXQA364F6 -p tcp -m tcp -j DNAT --to-destination 10.80.153.167:8000   所以得到：\n1 2 3  pod3:10.80.167.226 pod2:10.80.128.247 pod1:10.80.153.167   这些ip和上面的comment信息，均来自apiserver，apiserver最终是在etcd里面存储并及时更新并管理这些对象。\n为什么 gRPC 需要额外的负载均衡设置？ 首先需要一起来了解下，为什么 gRPC 需要额外的设置。\ngRPC 正逐渐成为应用开发者的常见选择。相比于其他服务协议，如基于 HTTP 的 JSON，gRPC 能够提供更好的特性，包括更低的（反）序列化开销、自动类型检查、格式化 API，以及更小的 TCP 管理开销。\n但是，gRPC 也打破了标准的连接层负载均衡约定，也就是 Kubernetes 中默认提供的负载均衡方式。这是因为 gRPC 是基于 HTTP/2 构建，而 HTTP/2 是面向单个 TCP 长连接进行设计的，全部的请求都会复用这一个 TCP 连接。通常情况下，这种方式很棒，因为这样可以减少连接管理的开销。但是，这也意味着（读者也可以想象到）连接层的负载均衡会失效。一旦连接创建之后，就不会再次触发负载均衡。指向某个 pod 的全部请求会封装在相同的连接之中，如下图所示：\n为什么 HTTP/1.1 不受影响？ 在 HTTP/1.1 中也存在相同的长连接概念，但却不存在类似问题。这是因为 HTTP/1.1 某些特性会使得 TCP 连接被回收。正因如此，连接层负载均衡对于 HTTP/1.1 来说就够用了，无需其他特殊配置。\n为了理解其中原理，需要深入了解一下 HTTP/1.1。与 HTTP/2 不同，HTTP/1.1 不支持请求复用。每个 TCP 连接在同一时间只能处理一个 HTTP 请求。假设客户端发起请求 GET /foo，需要一直等待直到服务端返回。在一个请求–应答周期内，该连接不能处理其他请求。\n通常情况下人们都希望多个请求能够并发处理。因此为了实现 HTTP/1.1 下的并发请求，需要创建多个 HTTP/1.1 连接，基于这些连接来发送全部请求。此外，HTTP/1.1 中的长连接在一段时间后是会过期的，过期连接会被客户端（或者服务端）销毁。在这两点共同作用下，HTTP/1.1 请求会在多个 TCP 连接之间进行循环，所以连接层的负载均衡才会生效。\ngRPC 如何实现负载均衡？ 回过头来看一下 gRPC。因为不能在连接层实现负载均衡，所以需要在应用层来完成。换句话说，需要为每个目标地址创建一个 HTTP/2 连接，对请求实现负载均衡，如下所示：\n在网络模型中，这意味着需要实现 L5/L7 层的负载均衡，而不是 L3/L4。这样就需要感知 TCP 连接上传输的协议格式。\n如何实现？有这么几种选择。第一种，可以在应用之中手工创建并维护目标地址的连接池，通过配置 gRPC 客户端使用该连接池来实现。这种方式控制起来最灵活，但是在 Kubernetes 这种环境中实现起来非常复杂，因为 Kubernetes 每次进行 pod 层面的调度，连接池都需要进行相应变更。应用需要监控 Kubernetes 的 API，并与 pod 信息保持实时同步。\n在 Kubernetes 中，还有另外一种方式，是将服务按照无状态方式进行部署。在该情况下，Kubernetes 会在 DNS 中为服务创建多条记录。如果所使用的 gRPC 客户端足够先进，就能通过上述多个 DNS 记录来实现负载均衡。但是这种实现方式依赖于使用特定的 gRPC 客户端，并且只能使用无状态模式部署服务。\n最后，还有第三种方式：使用一个轻量级代理。\n使用无头服务 Headless Service的负载均衡，是通过内部coredns进行dns解析pod所有地址列表进行的。\n1 2 3 4 5 6 7 8 9 10 11 12 13  kind:ServiceapiVersion:v1metadata:name:backendhspec:selector:app:backend#对应后端生产者或者消费者ports:- port:8000protocol:TCPtargetPort:8000clusterIP:None  在grpc的生产者与者消费者之间的通信，通过在发起方预埋变量名方式获取dns解析后向具体服务进行发起请求。\n在 Kubernetes 上使用 Linkerd 实现 gRPC 负载均衡 Linkerd 是一种基于 CNCF 的 Kubernetes 服务网格。Linkerd 通过 sidecar 的方式来实现负载均衡，可以单独部署到某个服务，甚至不需要集群许可。这意味着为服务添加 Linkerd，等价于为每个 pod 添加了一个很小并且很高效的代理，由这些代理来监控 Kubernetes 的 API，并自动实现 gRPC 的负载均衡。具体部署方式如下：\n使用 Linkerd 有如下几个好处。首先，Linkerd 支持任何语言下的 gRPC 客户端，也支持每种部署模式（无状态部署或者有状态部署）。这是因为 Linkerd 代理是在传输层完成，会自动对 HTTP/2 和 HTTP/1.x 进行检测，并实现 L7 层的负载均衡，而对其他的流量不做任何处理。这意味着不会产生额外的影响。\n其次，Linkerd 负载均衡是非常复杂的。除了需要监听 Kubernetes API，并且在 pod 发生调度后自动更新负载均衡的连接池之外，Linkerd 还会根据响应的延迟，使用指数级权重对请求进行调整，优先将请求发送到相应延迟低的 pod。如果某个 pod 响应很慢，甚至只是偶然抖动，Linkerd 都会将其上的流量摘掉。这样做可以减少端到端的延迟。\n最后，Linkerd 基于 rust 实现的代理体积非常小，并且速度快的难以置信。Linkerd 声称百分之 99 的请求开销小于 1ms，并且对于 pod 上物理内存的占用小于 10mb。这意味着 Linkerd 对于系统性能的影响可以忽略不计。\n测试 Linkerd 非常简单。只需要按照 Linkerd 入门介绍即可。在笔记本上安装 CLI，在集群上安装控制层，然后对服务“网格化”（将代理注入每个 pod）。Linkerd 立刻就能在服务中生效，并实现合理的 gRPC 路由。\n安装 Linkerd 之后，再看下选举服务：\n可以看到，CPU 图表中每个 pod 都被激活，表示每个 pod 都开始接受流量。而实现这些无需改动任何一行代码。哈哈，Linkerd 就像有魔力一般，实现了 gRPC 负载均衡。\nLinkerd 也提供了内置的流量大盘，所以也无需猜测 CPU 图表中的变化究竟代表着什么。下面就是 Linkerd 的大盘，包括每个 pod 的成功率，请求大小，以及延迟。\n可以看到每个 pod 每秒大概处理 5 个请求。同时通过大盘还能发现，服务成功率还存在一些问题需要解决。（在示例应用中，特意构造了一些异常，方便为读者演示可以通过 Linkerd 大盘来观察服务质量！）\n转载 Grpc在kubernetes集群中的负载均衡\n",
  "wordCount" : "3046",
  "inLanguage": "zh-cn",
  "datePublished": "2021-02-22T17:48:28Z",
  "dateModified": "2021-02-22T17:48:28Z",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "/post/grpc%E5%9C%A8k8s%E9%9B%86%E7%BE%A4%E4%B8%AD%E7%9A%84%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Forz Blog",
    "logo": {
      "@type": "ImageObject",
      "url": "/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>
<noscript>
    <style type="text/css">
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: #1d1e20;
                --entry: #2e2e33;
                --primary: rgba(255, 255, 255, 0.84);
                --secondary: rgba(255, 255, 255, 0.56);
                --tertiary: rgba(255, 255, 255, 0.16);
                --content: rgba(255, 255, 255, 0.74);
                --hljs-bg: #2e2e33;
                --code-bg: #37383e;
                --border: #333;
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="/" accesskey="h" title="Forz Blog (Alt + H)">Forz Blog</a>
            <span class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </span>
        </div>
        <ul id="menu">
            <li>
                <a href="/" title="Home">
                    <span>Home</span>
                </a>
            </li>
            <li>
                <a href="/post/" title="Archives">
                    <span>Archives</span>
                </a>
            </li>
            <li>
                <a href="/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
            <li>
                <a href="/categories/" title="Categories">
                    <span>Categories</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title">
      Grpc在k8s集群中的负载均衡
    </h1>
    <div class="post-meta">February 22, 2021
</div>
  </header> 
  <div class="post-content"><h2 id="背景">背景<a hidden class="anchor" aria-hidden="true" href="#背景">#</a></h2>
<p>很多刚刚接触 gRPC 的用户，通常会惊讶于 Kubernetes 默认提供的负载均衡对于 gRPC 来说无法实现开箱即用的效果。比如，将一个简单的基于 Node.js 实现的 gRPC 微服务部署在 Kubernetes 后，如下图所示：</p>
<p><img loading="lazy" src="https://blog-1257321977.cos.ap-beijing.myqcloud.com/20210222175941.png" alt=""  />
</p>
<p>尽管选举服务显示存在多个 pod，但是从 Kubernetes 的 CPU 图表可以清晰的看出，只有一个 pod 能够接收到流量，处于工作状态。这是为什么？</p>
<h2 id="service负载调度原理">service负载调度原理<a hidden class="anchor" aria-hidden="true" href="#service负载调度原理">#</a></h2>
<p>在k8s的文档中阐述了kube-proxy的特点：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-s" data-lang="s"><span class="n">The</span> <span class="n">kube</span> <span class="n">proxy</span><span class="o">:</span>

<span class="n">runs</span> <span class="n">on</span> <span class="n">each</span> <span class="n">node</span>  <span class="c1">#运行在每个节点</span>
<span class="n">proxies</span> <span class="n">UDP</span><span class="p">,</span> <span class="n">TCP</span> <span class="n">and</span> <span class="n">SCTP</span> <span class="c1">#可以代理UDP、TCP、SCTP协议</span>
<span class="n">does</span> <span class="n">not</span> <span class="n">understand</span> <span class="n">HTTP</span>  <span class="c1">#但是不能识别HTTP协议</span>
<span class="n">provides</span> <span class="n">load</span> <span class="n">balancing</span>  <span class="c1">#提供负载均衡</span>
<span class="n">is</span> <span class="n">just</span> <span class="n">used</span> <span class="n">to</span> <span class="n">reach</span> <span class="n">services</span> <span class="c1">#只用于到达服务</span>
</code></pre></td></tr></table>
</div>
</div><p>其中阐述了kube-proxy的iptbles代理，是不能支持应用层协议识别的。</p>
<p>创建service后，kubernetes会在kube-proxy里面设置iptables相应规则，从api-server获取到后端pod的ip以及端口情况。生产相应转发规则</p>
<p>当目标地址为service的地址10.97.211.12/32和目标端口为8000时，跳转到KUBE-SVC-EHPSUHUW2JIVMPQD链</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-s" data-lang="s"><span class="o">-</span><span class="n">A</span> <span class="n">KUBE</span><span class="o">-</span><span class="n">SERVICES</span> <span class="o">-</span><span class="n">d</span> <span class="m">10.97.211.12</span><span class="o">/</span><span class="m">32</span> <span class="o">-</span><span class="n">p</span> <span class="n">tcp</span> <span class="o">-</span><span class="n">m</span> <span class="n">comment</span>
<span class="o">--</span><span class="n">comment</span> <span class="s">&#34;default/backend:grpc cluster IP&#34;</span> <span class="o">-</span><span class="n">m</span> <span class="n">tcp</span> <span class="o">--</span><span class="n">dport</span> <span class="m">8000</span> <span class="n">\</span>
<span class="o">-</span><span class="n">j</span> <span class="n">KUBE</span><span class="o">-</span><span class="n">SVC</span><span class="o">-</span><span class="n">EHPSUHUW2JIVMPQD</span>
</code></pre></td></tr></table>
</div>
</div><p>链KUBE-SVC-EHPSUHUW2JIVMPQD为3条规则，副本数是3</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-s" data-lang="s"><span class="m">30.333</span>%的几率去<span class="n">KUBE</span><span class="o">-</span><span class="n">SEP</span><span class="o">-</span><span class="n">MPFDKKCFY2PBGU4S链</span>（<span class="n">pod1</span> 的<span class="n">ip</span>）
<span class="o">-</span><span class="n">A</span> <span class="n">KUBE</span><span class="o">-</span><span class="n">SVC</span><span class="o">-</span><span class="n">EHPSUHUW2JIVMPQD</span> <span class="o">-</span><span class="n">m</span> <span class="n">statistic</span> <span class="o">--</span><span class="n">mode</span> <span class="n">random</span> <span class="o">--</span><span class="n">probability</span> <span class="m">0.33332999982</span> <span class="n">\</span>
<span class="o">-</span><span class="n">j</span> <span class="n">KUBE</span><span class="o">-</span><span class="n">SEP</span><span class="o">-</span><span class="n">MPFDKKCFY2PBGU4S</span>
</code></pre></td></tr></table>
</div>
</div><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-s" data-lang="s"><span class="m">50</span>%的几率去<span class="n">KUBE</span><span class="o">-</span><span class="n">SEP</span><span class="o">-</span><span class="n">LMG22MVGXQA364F6链</span>（<span class="n">pod2的ip地址</span>）
<span class="o">-</span><span class="n">A</span> <span class="n">KUBE</span><span class="o">-</span><span class="n">SVC</span><span class="o">-</span><span class="n">EHPSUHUW2JIVMPQD</span> <span class="o">-</span><span class="n">m</span> <span class="n">statistic</span> <span class="o">--</span><span class="n">mode</span> <span class="n">random</span> <span class="o">--</span><span class="n">probability</span> <span class="m">0.50000000000</span> <span class="n">\</span>
<span class="o">-</span><span class="n">j</span> <span class="n">KUBE</span><span class="o">-</span><span class="n">SEP</span><span class="o">-</span><span class="n">LMG22MVGXQA364F6</span>
其余的全部走<span class="n">KUBE</span><span class="o">-</span><span class="n">SEP</span><span class="o">-</span><span class="n">EX64MF3TTLO7J5EC链</span>（<span class="n">pod3的ip地址</span>）
<span class="o">-</span><span class="n">A</span> <span class="n">KUBE</span><span class="o">-</span><span class="n">SVC</span><span class="o">-</span><span class="n">EHPSUHUW2JIVMPQD</span> <span class="o">-</span><span class="n">j</span> <span class="n">KUBE</span><span class="o">-</span><span class="n">SEP</span><span class="o">-</span><span class="n">EX64MF3TTLO7J5EC</span>
</code></pre></td></tr></table>
</div>
</div><p>pod3的ip地址</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-s" data-lang="s"><span class="o">-</span><span class="n">A</span> <span class="n">KUBE</span><span class="o">-</span><span class="n">SEP</span><span class="o">-</span><span class="n">EX64MF3TTLO7J5EC</span> <span class="o">-</span><span class="n">s</span> <span class="m">10.80.167.226</span><span class="o">/</span><span class="m">32</span> <span class="o">-</span><span class="n">j</span> <span class="n">KUBE</span><span class="o">-</span><span class="n">MARK</span><span class="o">-</span><span class="n">MASQ</span>
<span class="o">-</span><span class="n">A</span> <span class="n">KUBE</span><span class="o">-</span><span class="n">SEP</span><span class="o">-</span><span class="n">EX64MF3TTLO7J5EC</span> <span class="o">-</span><span class="n">p</span> <span class="n">tcp</span> <span class="o">-</span><span class="n">m</span> <span class="n">tcp</span> <span class="o">-</span><span class="n">j</span> <span class="n">DNAT</span> <span class="o">--</span><span class="n">to</span><span class="o">-</span><span class="n">destination</span> <span class="m">10.80.167.226</span><span class="o">:</span><span class="m">8000</span>
</code></pre></td></tr></table>
</div>
</div><p>pod1的ip地址</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-s" data-lang="s"><span class="o">-</span><span class="n">A</span> <span class="n">KUBE</span><span class="o">-</span><span class="n">SEP</span><span class="o">-</span><span class="n">MPFDKKCFY2PBGU4S</span> <span class="o">-</span><span class="n">s</span> <span class="m">10.80.128.247</span><span class="o">/</span><span class="m">32</span> <span class="o">-</span><span class="n">j</span> <span class="n">KUBE</span><span class="o">-</span><span class="n">MARK</span><span class="o">-</span><span class="n">MASQ</span>
<span class="o">-</span><span class="n">A</span> <span class="n">KUBE</span><span class="o">-</span><span class="n">SEP</span><span class="o">-</span><span class="n">MPFDKKCFY2PBGU4S</span> <span class="o">-</span><span class="n">p</span> <span class="n">tcp</span> <span class="o">-</span><span class="n">m</span> <span class="n">tcp</span> <span class="o">-</span><span class="n">j</span> <span class="n">DNAT</span> <span class="o">--</span><span class="n">to</span><span class="o">-</span><span class="n">destination</span> <span class="m">10.80.128.247</span><span class="o">:</span><span class="m">8000</span>
</code></pre></td></tr></table>
</div>
</div><p>pod2的ip地址</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-s" data-lang="s"><span class="o">-</span><span class="n">A</span> <span class="n">KUBE</span><span class="o">-</span><span class="n">SEP</span><span class="o">-</span><span class="n">LMG22MVGXQA364F6</span> <span class="o">-</span><span class="n">s</span> <span class="m">10.80.153.167</span><span class="o">/</span><span class="m">32</span> <span class="o">-</span><span class="n">j</span> <span class="n">KUBE</span><span class="o">-</span><span class="n">MARK</span><span class="o">-</span><span class="n">MASQ</span>
<span class="o">-</span><span class="n">A</span> <span class="n">KUBE</span><span class="o">-</span><span class="n">SEP</span><span class="o">-</span><span class="n">LMG22MVGXQA364F6</span> <span class="o">-</span><span class="n">p</span> <span class="n">tcp</span> <span class="o">-</span><span class="n">m</span> <span class="n">tcp</span> <span class="o">-</span><span class="n">j</span> <span class="n">DNAT</span> <span class="o">--</span><span class="n">to</span><span class="o">-</span><span class="n">destination</span> <span class="m">10.80.153.167</span><span class="o">:</span><span class="m">8000</span>
</code></pre></td></tr></table>
</div>
</div><p>所以得到：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-s" data-lang="s"><span class="n">pod3</span><span class="o">:</span><span class="m">10.80.167.226</span>
<span class="n">pod2</span><span class="o">:</span><span class="m">10.80.128.247</span>
<span class="n">pod1</span><span class="o">:</span><span class="m">10.80.153.167</span>
</code></pre></td></tr></table>
</div>
</div><p>这些ip和上面的comment信息，均来自apiserver，apiserver最终是在etcd里面存储并及时更新并管理这些对象。</p>
<h2 id="为什么-grpc-需要额外的负载均衡设置">为什么 gRPC 需要额外的负载均衡设置？<a hidden class="anchor" aria-hidden="true" href="#为什么-grpc-需要额外的负载均衡设置">#</a></h2>
<p>首先需要一起来了解下，为什么 gRPC 需要额外的设置。</p>
<p>gRPC 正逐渐成为应用开发者的常见选择。相比于其他服务协议，如基于 HTTP 的 JSON，gRPC 能够提供更好的特性，包括更低的（反）序列化开销、自动类型检查、格式化 API，以及更小的 TCP 管理开销。</p>
<p>但是，gRPC 也打破了标准的连接层负载均衡约定，也就是 Kubernetes 中默认提供的负载均衡方式。这是因为 gRPC 是基于 HTTP/2 构建，而 HTTP/2 是面向单个 TCP 长连接进行设计的，全部的请求都会复用这一个 TCP 连接。通常情况下，这种方式很棒，因为这样可以减少连接管理的开销。但是，这也意味着（读者也可以想象到）连接层的负载均衡会失效。一旦连接创建之后，就不会再次触发负载均衡。指向某个 pod 的全部请求会封装在相同的连接之中，如下图所示：</p>
<p><img loading="lazy" src="https://blog-1257321977.cos.ap-beijing.myqcloud.com/20210222180318.png" alt=""  />
</p>
<h2 id="为什么-http11-不受影响">为什么 HTTP/1.1 不受影响？<a hidden class="anchor" aria-hidden="true" href="#为什么-http11-不受影响">#</a></h2>
<p>在 HTTP/1.1 中也存在相同的长连接概念，但却不存在类似问题。这是因为 HTTP/1.1 某些特性会使得 TCP 连接被回收。正因如此，连接层负载均衡对于 HTTP/1.1 来说就够用了，无需其他特殊配置。</p>
<p>为了理解其中原理，需要深入了解一下 HTTP/1.1。与 HTTP/2 不同，HTTP/1.1 不支持请求复用。每个 TCP 连接在同一时间只能处理一个 HTTP 请求。假设客户端发起请求 GET /foo，需要一直等待直到服务端返回。在一个请求–应答周期内，该连接不能处理其他请求。</p>
<p>通常情况下人们都希望多个请求能够并发处理。因此为了实现 HTTP/1.1 下的并发请求，需要创建多个 HTTP/1.1 连接，基于这些连接来发送全部请求。此外，HTTP/1.1 中的长连接在一段时间后是会过期的，过期连接会被客户端（或者服务端）销毁。在这两点共同作用下，HTTP/1.1 请求会在多个 TCP 连接之间进行循环，所以连接层的负载均衡才会生效。</p>
<h2 id="grpc-如何实现负载均衡">gRPC 如何实现负载均衡？<a hidden class="anchor" aria-hidden="true" href="#grpc-如何实现负载均衡">#</a></h2>
<p>回过头来看一下 gRPC。因为不能在连接层实现负载均衡，所以需要在应用层来完成。换句话说，需要为每个目标地址创建一个 HTTP/2 连接，对请求实现负载均衡，如下所示：</p>
<p><img loading="lazy" src="https://blog-1257321977.cos.ap-beijing.myqcloud.com/20210222181037.png" alt=""  />
</p>
<p>在网络模型中，这意味着需要实现 L5/L7 层的负载均衡，而不是 L3/L4。这样就需要感知 TCP 连接上传输的协议格式。</p>
<p>如何实现？有这么几种选择。第一种，可以在应用之中手工创建并维护目标地址的连接池，通过配置 gRPC 客户端使用该连接池来实现。这种方式控制起来最灵活，但是在 Kubernetes 这种环境中实现起来非常复杂，因为 Kubernetes 每次进行 pod 层面的调度，连接池都需要进行相应变更。应用需要监控 Kubernetes 的 API，并与 pod 信息保持实时同步。</p>
<p>在 Kubernetes 中，还有另外一种方式，是将服务按照无状态方式进行部署。在该情况下，Kubernetes 会在 DNS 中为服务创建多条记录。如果所使用的 gRPC 客户端足够先进，就能通过上述多个 DNS 记录来实现负载均衡。但是这种实现方式依赖于使用特定的 gRPC 客户端，并且只能使用无状态模式部署服务。</p>
<p>最后，还有第三种方式：使用一个轻量级代理。</p>
<h2 id="使用无头服务">使用无头服务<a hidden class="anchor" aria-hidden="true" href="#使用无头服务">#</a></h2>
<p>Headless Service的负载均衡，是通过内部coredns进行dns解析pod所有地址列表进行的。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">Service</span><span class="w">
</span><span class="w"></span><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">v1</span><span class="w">
</span><span class="w"></span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">backendh</span><span class="w">
</span><span class="w"></span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">selector</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="nt">app</span><span class="p">:</span><span class="w"> </span><span class="l">backend</span><span class="w"> </span><span class="c">#对应后端生产者或者消费者</span><span class="w">
</span><span class="w">  </span><span class="nt">ports</span><span class="p">:</span><span class="w">
</span><span class="w">
</span><span class="w"></span>- <span class="nt">port</span><span class="p">:</span><span class="w"> </span><span class="m">8000</span><span class="w">
</span><span class="w">    </span><span class="nt">protocol</span><span class="p">:</span><span class="w"> </span><span class="l">TCP</span><span class="w">
</span><span class="w">    </span><span class="nt">targetPort</span><span class="p">:</span><span class="w"> </span><span class="m">8000</span><span class="w">
</span><span class="w">  </span><span class="nt">clusterIP</span><span class="p">:</span><span class="w"> </span><span class="l">None</span><span class="w">
</span></code></pre></td></tr></table>
</div>
</div><p>在grpc的生产者与者消费者之间的通信，通过在发起方预埋变量名方式获取dns解析后向具体服务进行发起请求。</p>
<h2 id="在-kubernetes-上使用-linkerd-实现-grpc-负载均衡">在 Kubernetes 上使用 Linkerd 实现 gRPC 负载均衡<a hidden class="anchor" aria-hidden="true" href="#在-kubernetes-上使用-linkerd-实现-grpc-负载均衡">#</a></h2>
<p>Linkerd 是一种基于 CNCF 的 Kubernetes 服务网格。Linkerd 通过 sidecar 的方式来实现负载均衡，可以单独部署到某个服务，甚至不需要集群许可。这意味着为服务添加 Linkerd，等价于为每个 pod 添加了一个很小并且很高效的代理，由这些代理来监控 Kubernetes 的 API，并自动实现 gRPC 的负载均衡。具体部署方式如下：</p>
<p><img loading="lazy" src="https://blog-1257321977.cos.ap-beijing.myqcloud.com/20210222181305.png" alt=""  />
</p>
<p>使用 Linkerd 有如下几个好处。首先，Linkerd 支持任何语言下的 gRPC 客户端，也支持每种部署模式（无状态部署或者有状态部署）。这是因为 Linkerd 代理是在传输层完成，会自动对 HTTP/2 和 HTTP/1.x 进行检测，并实现 L7 层的负载均衡，而对其他的流量不做任何处理。这意味着不会产生额外的影响。</p>
<p>其次，Linkerd 负载均衡是非常复杂的。除了需要监听 Kubernetes API，并且在 pod 发生调度后自动更新负载均衡的连接池之外，Linkerd 还会根据响应的延迟，使用指数级权重对请求进行调整，优先将请求发送到相应延迟低的 pod。如果某个 pod 响应很慢，甚至只是偶然抖动，Linkerd 都会将其上的流量摘掉。这样做可以减少端到端的延迟。</p>
<p>最后，Linkerd 基于 rust 实现的代理体积非常小，并且速度快的难以置信。Linkerd 声称百分之 99 的请求开销小于 1ms，并且对于 pod 上物理内存的占用小于 10mb。这意味着 Linkerd 对于系统性能的影响可以忽略不计。</p>
<p>测试 Linkerd 非常简单。只需要按照 Linkerd 入门介绍即可。在笔记本上安装 CLI，在集群上安装控制层，然后对服务“网格化”（将代理注入每个 pod）。Linkerd 立刻就能在服务中生效，并实现合理的 gRPC 路由。</p>
<p>安装 Linkerd 之后，再看下选举服务：</p>
<p><img loading="lazy" src="https://blog-1257321977.cos.ap-beijing.myqcloud.com/20210222181437.png" alt=""  />
</p>
<p>可以看到，CPU 图表中每个 pod 都被激活，表示每个 pod 都开始接受流量。而实现这些无需改动任何一行代码。哈哈，Linkerd 就像有魔力一般，实现了 gRPC 负载均衡。</p>
<p>Linkerd 也提供了内置的流量大盘，所以也无需猜测 CPU 图表中的变化究竟代表着什么。下面就是 Linkerd 的大盘，包括每个 pod 的成功率，请求大小，以及延迟。</p>
<p><img loading="lazy" src="https://blog-1257321977.cos.ap-beijing.myqcloud.com/20210222181457.png" alt=""  />
</p>
<p>可以看到每个 pod 每秒大概处理 5 个请求。同时通过大盘还能发现，服务成功率还存在一些问题需要解决。（在示例应用中，特意构造了一些异常，方便为读者演示可以通过 Linkerd 大盘来观察服务质量！）</p>
<h2 id="转载">转载<a hidden class="anchor" aria-hidden="true" href="#转载">#</a></h2>
<p><a href="https://www.sklinux.com/posts/k8s/grpc%E7%9A%84%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/">Grpc在kubernetes集群中的负载均衡</a></p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="/tags/k8s/">k8s</a></li>
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2021 <a href="/">Forz Blog</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://git.io/hugopapermod" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)">
    <button class="top-link" id="top-link" type="button" accesskey="g">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
            <path d="M12 6H0l6-6z" />
        </svg>
    </button>
</a>

<script>
    let menu = document.getElementById('menu')
    menu.scrollLeft = localStorage.getItem("menu-scroll-position");
    menu.onscroll = function () {
        localStorage.setItem("menu-scroll-position", menu.scrollLeft);
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
