<!DOCTYPE html>
<html lang="zh-cn" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>无人值守的自动dump | Forz Blog</title>
<meta name="keywords" content="Go" />
<meta name="description" content="Go 项目做的比较大(主要说代码多，参与人多)之后，可能会遇到类似下面这样的问题： 程序老是半夜崩，崩了以后就重启了，我也醒不来，现场早就丢了，不">
<meta name="author" content="">
<link rel="canonical" href="/post/%E6%97%A0%E4%BA%BA%E5%80%BC%E5%AE%88%E7%9A%84%E8%87%AA%E5%8A%A8dump/" />
<link crossorigin="anonymous" href="/assets/css/stylesheet.min.00d5d4fc479b1575183ee8d86b4fb372ba9d9b1904e96fa8e4c40ff7debe2b94.css" integrity="sha256-ANXU/EebFXUYPujYa0&#43;zcrqdmxkE6W&#43;o5MQP996&#43;K5Q=" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/assets/js/highlight.min.7680afc38aa6b15ddf158a4f3780b7b1f7dde7e91d26f073e6229bb7a0793c92.js" integrity="sha256-doCvw4qmsV3fFYpPN4C3sffd5&#43;kdJvBz5iKbt6B5PJI="
    onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="apple-touch-icon" href="/apple-touch-icon.png">
<link rel="mask-icon" href="/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<meta name="generator" content="Hugo 0.87.0" />
<meta property="og:title" content="无人值守的自动dump" />
<meta property="og:description" content="Go 项目做的比较大(主要说代码多，参与人多)之后，可能会遇到类似下面这样的问题： 程序老是半夜崩，崩了以后就重启了，我也醒不来，现场早就丢了，不" />
<meta property="og:type" content="article" />
<meta property="og:url" content="/post/%E6%97%A0%E4%BA%BA%E5%80%BC%E5%AE%88%E7%9A%84%E8%87%AA%E5%8A%A8dump/" /><meta property="article:section" content="post" />
<meta property="article:published_time" content="2021-06-08T19:39:18&#43;00:00" />
<meta property="article:modified_time" content="2021-06-08T19:39:18&#43;00:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="无人值守的自动dump"/>
<meta name="twitter:description" content="Go 项目做的比较大(主要说代码多，参与人多)之后，可能会遇到类似下面这样的问题： 程序老是半夜崩，崩了以后就重启了，我也醒不来，现场早就丢了，不"/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "/post/"
    }
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "无人值守的自动dump",
      "item": "/post/%E6%97%A0%E4%BA%BA%E5%80%BC%E5%AE%88%E7%9A%84%E8%87%AA%E5%8A%A8dump/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "无人值守的自动dump",
  "name": "无人值守的自动dump",
  "description": "Go 项目做的比较大(主要说代码多，参与人多)之后，可能会遇到类似下面这样的问题： 程序老是半夜崩，崩了以后就重启了，我也醒不来，现场早就丢了，不",
  "keywords": [
    "Go"
  ],
  "articleBody": "Go 项目做的比较大(主要说代码多，参与人多)之后，可能会遇到类似下面这样的问题：\n 程序老是半夜崩，崩了以后就重启了，我也醒不来，现场早就丢了，不知道怎么定位 这压测开压之后，随机出问题，可能两小时，也可能五小时以后才出问题，这我蹲点蹲出痔疮都不一定能等到崩溃的那个时间点啊 有些级联失败，最后留下现场并不能帮助我们准确地判断问题的根因，我们需要出问题时第一时间的现场  Go 内置的 pprof 虽然是问题定位的神器，但是没有办法让你恰好在出问题的那个时间点，把相应的现场保存下来进行分析。特别是一些随机出现的内存泄露、CPU 抖动，等你发现有泄露的时候，可能程序已经 OOM 被 kill 掉了。而 CPU 抖动，你可以蹲了一星期都不一定蹲得到。\n这个问题最好的解决办法是 continuous profiling，不过这个理念需要公司的监控系统配合，在没有达到最终目标前，我们可以先向前迈一小步，看看怎么用比较低的成本来解决这个问题。\n从现象上，可以将出问题的症状简单分个类：\n cpu 抖动：有可能是模块内有一些比较冷门的逻辑，触发概率比较低，比如半夜的定时脚本，触发了以后你还在睡觉，这时候要定位就比较闹心了。 内存使用抖动：有很多种情况会导致内存使用抖动，比如突然涌入了大量请求，导致本身创建了过多的对象。也可能是 goroutine 泄露。也可能是突然有锁冲突，也可能是突然有 IO 抖动。原因太多了，猜是没法猜出根因的。 goroutine 数暴涨，可能是死锁，可能是数据生产完了 channel 没关闭，也可能是 IO 抖了什么的。  CPU 使用，内存占用和 goroutine 数，都可以用数值表示，所以不管是“暴涨”还是抖动，都可以用简单的规则来表示：\n xx 突然比正常情况下的平均值高出了 25% xx 超过了模块正常情况下的最高水位线  这两条规则可以描述大部分情况下的异常，规则一可以表示瞬时的，剧烈的抖动，之后可能迅速恢复了；规则二可以用来表示那些缓慢上升，但最终超出系统负荷的情况，例如 1s 泄露一兆内存，直至几小时后 OOM。\n而与均值的 diff，在没有历史数据的情况下，就只能在程序内自行收集了，比如 goroutine 的数据，我们可以每 x 秒运行一次采集，在内存中保留最近 N 个周期的 goroutine 计数，并持续与之前记录的 goroutine 数据均值进行 diff：\n比如像图里的情况，前十个周期收集到的 goroutine 数在 1300 左右波动，而最新周期收集到的数据为 2w+，这显然是瞬时触发导致的异常情况，那么我们就可以在这个点自动地去做一些事情，比如：\n 把当前的 goroutine 栈 dump 下来 把当前的 cpu profile dump 下来 把当前的 off-cpu profile dump 下来  不怕死的话，也可以 dump 几秒的 trace\n文件保存下来，模块挂掉也就无所谓了。之后在喝茶的时候，发现线上曾经出现过崩溃，那再去线上机器把文件捞下来，一边喝茶一边分析，还是比较悠哉的。\n这里面稍微麻烦一些的是 CPU 和内存使用量的采集，现在的应用可能跑在物理机上，也可能跑在 docker 中，因此在获取用量时，需要我们自己去做一些定制。物理机中的数据采集，可以使用 gopsutil，docker 中的数据采集，可以参考少量 cgroups 中的实现。\nOOM 类问题 RPC decode 未做防御性编程，导致 OOM 应用侧的编解码可能是非官方实现(如 node 之类的无官方 SDK 的项目)，在一些私有协议 decode 工程中会读诸如 list len 之类的字段，如果外部编码实现有问题，发生了字节错位，就可能会读出一个很大的值。\n非标准 app —-encode——- 我们的应用 decode —– Boom!\ndecoder 实现都是需要考虑这种情况的，类似这样。如果对请求方的数据完全信任，碰到对方的 bug 或者恶意攻击，可能导致自己的服务 OOM。\n在线上实际发现了一例内存瞬间飚升的 case，收到报警后，我们可以看到：\n1 2  1: 1330208768 [1: 1330208768] @ 0x11b1df3 0x11b1bcb 0x119664e 0x11b1695 0x1196f77 0x11a956a 0x11a86c7 0x1196724 0x11b1695 0x11b1c29 0x119664e 0x11b1695 0x11b1c29 0x119664e 0x11b1695 0x11b1c29 0x119664e 0x11bb360 0x168f143 0x179c2fc 0x1799b70 0x179acd6 0x16d3306 0x16d1088 0xf59386 0xf59474 0xf54e5f 0xf54987 0xf539f1 0xf6043a 0xcd8c0d 0x49b481 ....下面是表示栈内容的，这不重要   1: 1330208768 [1: 1330208768] 表示 inuse_objects : inuse_space [alloc_objects : alloc_space]，这里可以看到一个对象就直接用掉了 1GB 内存，显然不是正常情况，查看代码后，发现有未进行大小判断而完全信任用户输入数据包的 decode 代码。\n修复起来很简单，像前面提到的 async-h1 一样加个判断就可以了。\ntls 开启后线上进程占用内存上涨，直至 OOM 线上需要做全链路加密，所以有开启 tls 的需求，但开启之后发现内存一路暴涨，直至 OOM，工具可以打印如下堆栈：\n1 2 3 4  heap profile: 1460: 27614136 [45557: 1080481472] @ heap/1048576 727: 23822336 [730: 23920640] @ 0xc56b96 0xc591e8 0xc58e68 0xc59ed1 0xdd55ff 0xde15b8 0xde13ef 0xde09e9 0xde050c 0x13bfa13 0x13bf475 0x14c33d0 0x14c49f8 0x14cb398 0x14bffab 0x14cdf78 0xddcf90 0x45eda1 # 0xc56b95 *****mtls/crypto/tls.(*block).reserve+0x75*****mtls/crypto/tls/conn.go:475   查阅老版本的 Go 代码，发现其 TLS 的 write buffer 会随着写出的数据包大小增加而逐渐扩容，其扩容逻辑比较简单：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  func (b *block) reserve(n int) { if cap(b.data) = n { return } m := cap(b.data) if m == 0 { m = 1024 } for m  n { m*= 2 } data := make([]byte, len(b.data), m) copy(data, b.data) b.data = data }   初始为 1024，后续不够用每次扩容为两倍。但是阅读 tls 的代码后得知，这个写出的数据包大小最大实际上只有 16KB + 额外的一个小 header 大小左右，但老版本的实现会导致比较多的空间浪费，因为最终会扩容到 32KB。\n这段比较浪费空间的逻辑在 Go1.12 之后已经进行了优化：\n1 2 3 4 5 6 7 8 9 10  func sliceForAppend(in []byte, n int) (head, tail []byte) { if total := len(in) + n; cap(in) = total { head = in[:total] } else { head = make([]byte, total) copy(head, in) } tail = head[len(in):] return }   变成了需要多少，分配多少的朴实逻辑。所以会比老版本在这个问题上有不少缓解，不过在我们的场景下，新版本的代码依然没法满足需求，所以还需要进一步优化，这就是后话了。\ngoroutine 暴涨类问题 本地 app GC hang 死，导致 goroutine 卡 channel send 在我们的程序中有一段和本地进程通信的逻辑，write goroutine 会向一个 channel 中写数据，按常理来讲，同物理机的两个进程通过网络通信成本比较低，类似下面的代码按说不太可能出问题：\n1 2 3 4 5 6 7 8  concurrently: taskChan  task consumer: for task := range taskChan { // 憋一些 task 一起写  localConnection.write(task 们) }   看起来问题不大，但是线上经常都有和这个 channel send 相关的抖动，我们通过工具拿到的现场：\n1 2 3 4 5 6  2020-11-03 08:00:05,950 [ERROR] [diag.goroutine] [diagnose] pprof goroutine, config_min : 3000, config_diff : 25, config_abs : 200000, previous : [41402 44257 47247 50085 52795 55509 29762 32575 35451 38460], current : 55509, profile : goroutine profile: total 55513 40844 @ 0x46daaf 0x4433ab 0x443381 0x443165 0xf551f7 0x12fd2e7 0x12fc94f 0x13f41d5 0x13fc45f 0xf43ee4 0xcd8c0d 0x49b481 # ****channel.Send 这是个假的栈，你理解意思就行了 #   当前憋了 5w 个 goroutine，有 4w 个卡在 channel send 上，这个 channel 的对面还是一条本地连接，令人难以接受。\n但是要考虑到，线上的业务系统是 Java，Java 发生 FGÇ 的时候可不是闹着玩的。对往本地连接的 write buffer 写数据一定不会卡的假设是有问题的。\n既然出问题了，说明在这里对我们的程序进行保护是必要的，修改起来也很简单，给 channel send 加一个超时就可以了。\n应用逻辑死锁，导致连接不可用，大量 goroutine 阻塞在 lock 上 大多数网络程序里，我们需要在发送应用层心跳，以保证在一些异常情况(比如拔网线)下，能够把那些无效连接从连接池里剔除掉。\n对于我们的场景来说，客户端向外创建的连接，如果一直没有请求，那么每隔一段时间会向外发送一个应用心跳请求，如果心跳连续失败(超时) N 次，那么将该连接进行关闭。\n在这个场景下会涉及到两把锁：\n 对连接进行操作的锁 conn lock 记录心跳请求的 request map lock  心跳成功的流程：收到心跳响应包，获取 conn lock - 获取 request map lock 心跳失败的流程：timer 超时，获取 request map lock - 需要关闭连接 - 获取 conn lock\n可以看出来，心跳的成功和失败流程并发时，获取锁的流程符合死锁的一般定义：持有锁、非抢占、循环等待。\n这个 bug 比较难触发，因为心跳失败要失败 N 次才会关闭连接，而正好在最后一次发生了心跳成功和失败并发才会触发上述的死锁，线上可以通过 goroutine 短时间的上涨发现这个问题，goroutine 的现场也是可以看得到的。简单分析就可以发现这个死锁问题(因为后续的流程都会卡在其中一把锁上)。\n知道原因解决起来就不麻烦了，涉及到一些具体的业务逻辑，这里就不赘述了。\nCPU 尖刺问题 应用逻辑导致死循环问题 国际化业务涉及到冬夏令时的切换，从夏令时切换到冬令时，会将时钟向前拔一个月，但天级日志轮转时，会根据轮转前的时间计算 24 小时后的时间，并按与 24:00 的差值来进行 time.Sleep，这时会发现整个应用的 CPU 飚高。自动采样结果发现一直在循环计算时间和重命名文件。\nlist 一下相关的函数，能很快地发现执行死循环的代码位置。这里就不截真实代码了，随便举个例子：\n1 2 3 4 5 6  .  .  23:func cpuex(wr http.ResponseWriter, req *http.Request) { .  .  24:\tgo func() { 17.73s 19.37s 25:\tfor { .  .  26:\t} .  .  27:\t}() .  .  28:}   转载 无人值守的自动 dump(一)\n无人值守的自动 dump(二)\n",
  "wordCount" : "3140",
  "inLanguage": "zh-cn",
  "datePublished": "2021-06-08T19:39:18Z",
  "dateModified": "2021-06-08T19:39:18Z",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "/post/%E6%97%A0%E4%BA%BA%E5%80%BC%E5%AE%88%E7%9A%84%E8%87%AA%E5%8A%A8dump/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Forz Blog",
    "logo": {
      "@type": "ImageObject",
      "url": "/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>
<noscript>
    <style type="text/css">
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: #1d1e20;
                --entry: #2e2e33;
                --primary: rgba(255, 255, 255, 0.84);
                --secondary: rgba(255, 255, 255, 0.56);
                --tertiary: rgba(255, 255, 255, 0.16);
                --content: rgba(255, 255, 255, 0.74);
                --hljs-bg: #2e2e33;
                --code-bg: #37383e;
                --border: #333;
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="/" accesskey="h" title="Forz Blog (Alt + H)">Forz Blog</a>
            <span class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </span>
        </div>
        <ul id="menu">
            <li>
                <a href="/" title="Home">
                    <span>Home</span>
                </a>
            </li>
            <li>
                <a href="/post/" title="Archives">
                    <span>Archives</span>
                </a>
            </li>
            <li>
                <a href="/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
            <li>
                <a href="/categories/" title="Categories">
                    <span>Categories</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title">
      无人值守的自动dump
    </h1>
    <div class="post-meta">June 8, 2021
</div>
  </header> 
  <div class="post-content"><p>Go 项目做的比较大(主要说代码多，参与人多)之后，可能会遇到类似下面这样的问题：</p>
<ul>
<li>程序老是半夜崩，崩了以后就重启了，我也醒不来，现场早就丢了，不知道怎么定位</li>
<li>这压测开压之后，随机出问题，可能两小时，也可能五小时以后才出问题，这我蹲点蹲出痔疮都不一定能等到崩溃的那个时间点啊</li>
<li>有些级联失败，最后留下现场并不能帮助我们准确地判断问题的根因，我们需要出问题时第一时间的现场</li>
</ul>
<p><img loading="lazy" src="https://blog-1257321977.cos.ap-beijing.myqcloud.com/20210608194547.png" alt=""  />
</p>
<p>Go 内置的 pprof 虽然是问题定位的神器，但是没有办法让你恰好在出问题的那个时间点，把相应的现场保存下来进行分析。特别是一些随机出现的内存泄露、CPU 抖动，等你发现有泄露的时候，可能程序已经 OOM 被 kill 掉了。而 CPU 抖动，你可以蹲了一星期都不一定蹲得到。</p>
<p>这个问题最好的解决办法是 continuous profiling，不过这个理念需要公司的监控系统配合，在没有达到最终目标前，我们可以先向前迈一小步，看看怎么用比较低的成本来解决这个问题。</p>
<p>从现象上，可以将出问题的症状简单分个类：</p>
<ul>
<li>cpu 抖动：有可能是模块内有一些比较冷门的逻辑，触发概率比较低，比如半夜的定时脚本，触发了以后你还在睡觉，这时候要定位就比较闹心了。</li>
<li>内存使用抖动：有很多种情况会导致内存使用抖动，比如突然涌入了大量请求，导致本身创建了过多的对象。也可能是 goroutine 泄露。也可能是突然有锁冲突，也可能是突然有 IO 抖动。原因太多了，猜是没法猜出根因的。</li>
<li>goroutine 数暴涨，可能是死锁，可能是数据生产完了 channel 没关闭，也可能是 IO 抖了什么的。</li>
</ul>
<p>CPU 使用，内存占用和 goroutine 数，都可以用数值表示，所以不管是“暴涨”还是抖动，都可以用简单的规则来表示：</p>
<ul>
<li>xx 突然比正常情况下的平均值高出了 25%</li>
<li>xx 超过了模块正常情况下的最高水位线</li>
</ul>
<p>这两条规则可以描述大部分情况下的异常，规则一可以表示瞬时的，剧烈的抖动，之后可能迅速恢复了；规则二可以用来表示那些缓慢上升，但最终超出系统负荷的情况，例如 1s 泄露一兆内存，直至几小时后 OOM。</p>
<p>而与均值的 diff，在没有历史数据的情况下，就只能在程序内自行收集了，比如 goroutine 的数据，我们可以每 x 秒运行一次采集，在内存中保留最近 N 个周期的 goroutine 计数，并持续与之前记录的 goroutine 数据均值进行 diff：</p>
<p><img loading="lazy" src="https://blog-1257321977.cos.ap-beijing.myqcloud.com/20210608194827.png" alt=""  />
</p>
<p>比如像图里的情况，前十个周期收集到的 goroutine 数在 1300 左右波动，而最新周期收集到的数据为 2w+，这显然是瞬时触发导致的异常情况，那么我们就可以在这个点自动地去做一些事情，比如：</p>
<ul>
<li>把当前的 goroutine 栈 dump 下来</li>
<li>把当前的 cpu profile dump 下来</li>
<li>把当前的 off-cpu profile dump 下来</li>
</ul>
<p>不怕死的话，也可以 dump 几秒的 trace</p>
<p>文件保存下来，模块挂掉也就无所谓了。之后在喝茶的时候，发现线上曾经出现过崩溃，那再去线上机器把文件捞下来，一边喝茶一边分析，还是比较悠哉的。</p>
<p>这里面稍微麻烦一些的是 CPU 和内存使用量的采集，现在的应用可能跑在物理机上，也可能跑在 docker 中，因此在获取用量时，需要我们自己去做一些定制。物理机中的数据采集，可以使用 gopsutil，docker 中的数据采集，可以参考少量 cgroups 中的实现。</p>
<h2 id="oom-类问题">OOM 类问题<a hidden class="anchor" aria-hidden="true" href="#oom-类问题">#</a></h2>
<h3 id="rpc-decode-未做防御性编程导致-oom">RPC decode 未做防御性编程，导致 OOM<a hidden class="anchor" aria-hidden="true" href="#rpc-decode-未做防御性编程导致-oom">#</a></h3>
<p>应用侧的编解码可能是非官方实现(如 node 之类的无官方 SDK 的项目)，在一些私有协议 decode 工程中会读诸如 list len 之类的字段，如果外部编码实现有问题，发生了字节错位，就可能会读出一个很大的值。</p>
<p>非标准 app &mdash;-encode&mdash;&mdash;-&gt; 我们的应用 decode &mdash;&ndash;&gt; Boom!</p>
<p>decoder 实现都是需要考虑这种情况的，类似这样。如果对请求方的数据完全信任，碰到对方的 bug 或者恶意攻击，可能导致自己的服务 OOM。</p>
<p>在线上实际发现了一例内存瞬间飚升的 case，收到报警后，我们可以看到：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-s" data-lang="s"><span class="m">1</span><span class="o">:</span> <span class="m">1330208768</span> <span class="n">[1</span><span class="o">:</span> <span class="m">1330208768</span><span class="n">]</span> <span class="o">@</span> <span class="mh">0x11b1df3</span> <span class="mh">0x11b1bcb</span> <span class="mh">0x119664e</span> <span class="mh">0x11b1695</span> <span class="mh">0x1196f77</span> <span class="mh">0x11a956a</span> <span class="mh">0x11a86c7</span> <span class="mh">0x1196724</span> <span class="mh">0x11b1695</span> <span class="mh">0x11b1c29</span> <span class="mh">0x119664e</span> <span class="mh">0x11b1695</span> <span class="mh">0x11b1c29</span> <span class="mh">0x119664e</span> <span class="mh">0x11b1695</span> <span class="mh">0x11b1c29</span> <span class="mh">0x119664e</span> <span class="mh">0x11bb360</span> <span class="mh">0x168f143</span> <span class="mh">0x179c2fc</span> <span class="mh">0x1799b70</span> <span class="mh">0x179acd6</span> <span class="mh">0x16d3306</span> <span class="mh">0x16d1088</span> <span class="mh">0xf59386</span> <span class="mh">0xf59474</span> <span class="mh">0xf54e5f</span> <span class="mh">0xf54987</span> <span class="mh">0xf539f1</span> <span class="mh">0xf6043a</span> <span class="mh">0xcd8c0d</span> <span class="mh">0x49b481</span>
<span class="n">....下面是表示栈内容的</span>，这不重要
</code></pre></td></tr></table>
</div>
</div><p>1: 1330208768 [1: 1330208768] 表示 inuse_objects : inuse_space [alloc_objects : alloc_space]，这里可以看到一个对象就直接用掉了 1GB 内存，显然不是正常情况，查看代码后，发现有未进行大小判断而完全信任用户输入数据包的 decode 代码。</p>
<p>修复起来很简单，像前面提到的 async-h1 一样加个判断就可以了。</p>
<h3 id="tls-开启后线上进程占用内存上涨直至-oom">tls 开启后线上进程占用内存上涨，直至 OOM<a hidden class="anchor" aria-hidden="true" href="#tls-开启后线上进程占用内存上涨直至-oom">#</a></h3>
<p>线上需要做全链路加密，所以有开启 tls 的需求，但开启之后发现内存一路暴涨，直至 OOM，工具可以打印如下堆栈：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-s" data-lang="s"><span class="n">heap</span> <span class="n">profile</span><span class="o">:</span> <span class="m">1460</span><span class="o">:</span> <span class="m">27614136</span> <span class="n">[45557</span><span class="o">:</span> <span class="m">1080481472</span><span class="n">]</span> <span class="o">@</span> <span class="n">heap</span><span class="o">/</span><span class="m">1048576</span>
<span class="m">727</span><span class="o">:</span> <span class="m">23822336</span> <span class="n">[730</span><span class="o">:</span> <span class="m">23920640</span><span class="n">]</span> <span class="o">@</span> <span class="mh">0xc56b96</span> <span class="mh">0xc591e8</span> <span class="mh">0xc58e68</span> <span class="mh">0xc59ed1</span> <span class="mh">0xdd55ff</span> <span class="mh">0xde15b8</span> <span class="mh">0xde13ef</span> <span class="mh">0xde09e9</span> <span class="mh">0xde050c</span> <span class="mh">0x13bfa13</span> <span class="mh">0x13bf475</span> <span class="mh">0x14c33d0</span> <span class="mh">0x14c49f8</span> <span class="mh">0x14cb398</span> <span class="mh">0x14bffab</span> <span class="mh">0x14cdf78</span> <span class="mh">0xddcf90</span> <span class="mh">0x45eda1</span>

<span class="c1"># 0xc56b95  *****mtls/crypto/tls.(*block).reserve+0x75*****mtls/crypto/tls/conn.go:475</span>
</code></pre></td></tr></table>
</div>
</div><p>查阅老版本的 Go 代码，发现其 TLS 的 write buffer 会随着写出的数据包大小增加而逐渐扩容，其扩容逻辑比较简单：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-go" data-lang="go"><span class="kd">func</span> <span class="p">(</span><span class="nx">b</span> <span class="o">*</span><span class="nx">block</span><span class="p">)</span> <span class="nf">reserve</span><span class="p">(</span><span class="nx">n</span> <span class="kt">int</span><span class="p">)</span> <span class="p">{</span>
	<span class="k">if</span> <span class="nb">cap</span><span class="p">(</span><span class="nx">b</span><span class="p">.</span><span class="nx">data</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="nx">n</span> <span class="p">{</span>
		<span class="k">return</span>
	<span class="p">}</span>
	<span class="nx">m</span> <span class="o">:=</span> <span class="nb">cap</span><span class="p">(</span><span class="nx">b</span><span class="p">.</span><span class="nx">data</span><span class="p">)</span>
	<span class="k">if</span> <span class="nx">m</span> <span class="o">==</span> <span class="mi">0</span> <span class="p">{</span>
		<span class="nx">m</span> <span class="p">=</span> <span class="mi">1024</span>
	<span class="p">}</span>
	<span class="k">for</span> <span class="nx">m</span> <span class="p">&lt;</span> <span class="nx">n</span> <span class="p">{</span>
<span class="nx">m</span><span class="o">*=</span> <span class="mi">2</span>
	<span class="p">}</span>
	<span class="nx">data</span> <span class="o">:=</span> <span class="nb">make</span><span class="p">([]</span><span class="kt">byte</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="nx">b</span><span class="p">.</span><span class="nx">data</span><span class="p">),</span> <span class="nx">m</span><span class="p">)</span>
	<span class="nb">copy</span><span class="p">(</span><span class="nx">data</span><span class="p">,</span> <span class="nx">b</span><span class="p">.</span><span class="nx">data</span><span class="p">)</span>
	<span class="nx">b</span><span class="p">.</span><span class="nx">data</span> <span class="p">=</span> <span class="nx">data</span>
<span class="p">}</span>
</code></pre></td></tr></table>
</div>
</div><p>初始为 1024，后续不够用每次扩容为两倍。但是阅读 tls 的代码后得知，这个写出的数据包大小最大实际上只有 16KB + 额外的一个小 header 大小左右，但老版本的实现会导致比较多的空间浪费，因为最终会扩容到 32KB。</p>
<p>这段比较浪费空间的逻辑在 Go1.12 之后已经进行了优化：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-go" data-lang="go"><span class="kd">func</span> <span class="nf">sliceForAppend</span><span class="p">(</span><span class="nx">in</span> <span class="p">[]</span><span class="kt">byte</span><span class="p">,</span> <span class="nx">n</span> <span class="kt">int</span><span class="p">)</span> <span class="p">(</span><span class="nx">head</span><span class="p">,</span> <span class="nx">tail</span> <span class="p">[]</span><span class="kt">byte</span><span class="p">)</span> <span class="p">{</span>
	<span class="k">if</span> <span class="nx">total</span> <span class="o">:=</span> <span class="nb">len</span><span class="p">(</span><span class="nx">in</span><span class="p">)</span> <span class="o">+</span> <span class="nx">n</span><span class="p">;</span> <span class="nb">cap</span><span class="p">(</span><span class="nx">in</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="nx">total</span> <span class="p">{</span>
		<span class="nx">head</span> <span class="p">=</span> <span class="nx">in</span><span class="p">[:</span><span class="nx">total</span><span class="p">]</span>
	<span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
		<span class="nx">head</span> <span class="p">=</span> <span class="nb">make</span><span class="p">([]</span><span class="kt">byte</span><span class="p">,</span> <span class="nx">total</span><span class="p">)</span>
		<span class="nb">copy</span><span class="p">(</span><span class="nx">head</span><span class="p">,</span> <span class="nx">in</span><span class="p">)</span>
	<span class="p">}</span>
	<span class="nx">tail</span> <span class="p">=</span> <span class="nx">head</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="nx">in</span><span class="p">):]</span>
	<span class="k">return</span>
<span class="p">}</span>
</code></pre></td></tr></table>
</div>
</div><p>变成了需要多少，分配多少的朴实逻辑。所以会比老版本在这个问题上有不少缓解，不过在我们的场景下，新版本的代码依然没法满足需求，所以还需要进一步优化，这就是后话了。</p>
<h2 id="goroutine-暴涨类问题">goroutine 暴涨类问题<a hidden class="anchor" aria-hidden="true" href="#goroutine-暴涨类问题">#</a></h2>
<p>本地 app GC hang 死，导致 goroutine 卡 channel send
在我们的程序中有一段和本地进程通信的逻辑，write goroutine 会向一个 channel 中写数据，按常理来讲，同物理机的两个进程通过网络通信成本比较低，类似下面的代码按说不太可能出问题：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-go" data-lang="go"><span class="nx">concurrently</span><span class="p">:</span>
<span class="nx">taskChan</span> <span class="o">&lt;-</span> <span class="nx">task</span>

<span class="nx">consumer</span><span class="p">:</span>
<span class="k">for</span> <span class="nx">task</span> <span class="o">:=</span> <span class="k">range</span> <span class="nx">taskChan</span> <span class="p">{</span>
    <span class="c1">// 憋一些 task 一起写
</span><span class="c1"></span>    <span class="nx">localConnection</span><span class="p">.</span><span class="nf">write</span><span class="p">(</span><span class="nx">task</span> <span class="nx">们</span><span class="p">)</span>
<span class="p">}</span>
</code></pre></td></tr></table>
</div>
</div><p>看起来问题不大，但是线上经常都有和这个 channel send 相关的抖动，我们通过工具拿到的现场：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-s" data-lang="s"><span class="m">2020-11-03</span> <span class="m">08</span><span class="o">:</span><span class="m">00</span><span class="o">:</span><span class="m">05</span><span class="p">,</span><span class="m">950</span> <span class="n">[ERROR]</span> <span class="n">[diag.goroutine]</span> <span class="n">[diagnose]</span> <span class="n">pprof</span> <span class="n">goroutine</span><span class="p">,</span> <span class="n">config_min</span> <span class="o">:</span> <span class="m">3000</span><span class="p">,</span> <span class="n">config_diff</span> <span class="o">:</span> <span class="m">25</span><span class="p">,</span> <span class="n">config_abs</span> <span class="o">:</span> <span class="m">200000</span><span class="p">,</span>  <span class="n">previous</span> <span class="o">:</span> <span class="n">[41402</span> <span class="m">44257</span> <span class="m">47247</span> <span class="m">50085</span> <span class="m">52795</span> <span class="m">55509</span> <span class="m">29762</span> <span class="m">32575</span> <span class="m">35451</span> <span class="m">38460</span><span class="n">]</span><span class="p">,</span> <span class="n">current</span> <span class="o">:</span> <span class="m">55509</span><span class="p">,</span> <span class="n">profile</span> <span class="o">:</span> <span class="n">goroutine</span> <span class="n">profile</span><span class="o">:</span> <span class="n">total</span> <span class="m">55513</span>
<span class="m">40844</span> <span class="o">@</span> <span class="mh">0x46daaf</span> <span class="mh">0x4433ab</span> <span class="mh">0x443381</span> <span class="mh">0x443165</span> <span class="mh">0xf551f7</span> <span class="mh">0x12fd2e7</span> <span class="mh">0x12fc94f</span> <span class="mh">0x13f41d5</span> <span class="mh">0x13fc45f</span> <span class="mh">0xf43ee4</span> <span class="mh">0xcd8c0d</span> <span class="mh">0x49b481</span>

<span class="c1"># ****channel.Send 这是个假的栈，你理解意思就行了</span>

<span class="c1">#</span>
</code></pre></td></tr></table>
</div>
</div><p>当前憋了 5w 个 goroutine，有 4w 个卡在 channel send 上，这个 channel 的对面还是一条本地连接，令人难以接受。</p>
<p>但是要考虑到，线上的业务系统是 Java，Java 发生 FGÇ 的时候可不是闹着玩的。对往本地连接的 write buffer 写数据一定不会卡的假设是有问题的。</p>
<p>既然出问题了，说明在这里对我们的程序进行保护是必要的，修改起来也很简单，给 channel send 加一个超时就可以了。</p>
<h3 id="应用逻辑死锁导致连接不可用大量-goroutine-阻塞在-lock-上">应用逻辑死锁，导致连接不可用，大量 goroutine 阻塞在 lock 上<a hidden class="anchor" aria-hidden="true" href="#应用逻辑死锁导致连接不可用大量-goroutine-阻塞在-lock-上">#</a></h3>
<p>大多数网络程序里，我们需要在发送应用层心跳，以保证在一些异常情况(比如拔网线)下，能够把那些无效连接从连接池里剔除掉。</p>
<p>对于我们的场景来说，客户端向外创建的连接，如果一直没有请求，那么每隔一段时间会向外发送一个应用心跳请求，如果心跳连续失败(超时) N 次，那么将该连接进行关闭。</p>
<p>在这个场景下会涉及到两把锁：</p>
<ul>
<li>对连接进行操作的锁 conn lock</li>
<li>记录心跳请求的 request map lock</li>
</ul>
<p>心跳成功的流程：收到心跳响应包，获取 conn lock -&gt; 获取 request map lock
心跳失败的流程：timer 超时，获取 request map lock -&gt; 需要关闭连接 -&gt; 获取 conn lock</p>
<p>可以看出来，心跳的成功和失败流程并发时，获取锁的流程符合死锁的一般定义：持有锁、非抢占、循环等待。</p>
<p>这个 bug 比较难触发，因为心跳失败要失败 N 次才会关闭连接，而正好在最后一次发生了心跳成功和失败并发才会触发上述的死锁，线上可以通过 goroutine 短时间的上涨发现这个问题，goroutine 的现场也是可以看得到的。简单分析就可以发现这个死锁问题(因为后续的流程都会卡在其中一把锁上)。</p>
<p>知道原因解决起来就不麻烦了，涉及到一些具体的业务逻辑，这里就不赘述了。</p>
<h2 id="cpu-尖刺问题">CPU 尖刺问题<a hidden class="anchor" aria-hidden="true" href="#cpu-尖刺问题">#</a></h2>
<h3 id="应用逻辑导致死循环问题">应用逻辑导致死循环问题<a hidden class="anchor" aria-hidden="true" href="#应用逻辑导致死循环问题">#</a></h3>
<p>国际化业务涉及到冬夏令时的切换，从夏令时切换到冬令时，会将时钟向前拔一个月，但天级日志轮转时，会根据轮转前的时间计算 24 小时后的时间，并按与 24:00 的差值来进行 time.Sleep，这时会发现整个应用的 CPU 飚高。自动采样结果发现一直在循环计算时间和重命名文件。</p>
<p>list 一下相关的函数，能很快地发现执行死循环的代码位置。这里就不截真实代码了，随便举个例子：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-s" data-lang="s">        <span class="n">. </span>         <span class="n">. </span>    <span class="m">23</span><span class="o">:</span><span class="n">func</span> <span class="nf">cpuex</span><span class="p">(</span><span class="n">wr</span> <span class="n">http.ResponseWriter</span><span class="p">,</span> <span class="n">req</span> <span class="o">*</span><span class="n">http.Request</span><span class="p">)</span> <span class="p">{</span>
         <span class="n">. </span>         <span class="n">. </span>    <span class="m">24</span><span class="o">:</span>	<span class="n">go</span> <span class="nf">func</span><span class="p">()</span> <span class="p">{</span>
    <span class="m">17.73</span><span class="n">s</span>     <span class="m">19.37</span><span class="n">s</span>     <span class="m">25</span><span class="o">:</span>		<span class="n">for</span> <span class="p">{</span>
         <span class="n">. </span>         <span class="n">. </span>    <span class="m">26</span><span class="o">:</span>		<span class="p">}</span>
         <span class="n">. </span>         <span class="n">. </span>    <span class="m">27</span><span class="o">:</span>	<span class="p">}()</span>
         <span class="n">. </span>         <span class="n">. </span>    <span class="m">28</span><span class="o">:</span><span class="p">}</span>
</code></pre></td></tr></table>
</div>
</div><h2 id="转载">转载<a hidden class="anchor" aria-hidden="true" href="#转载">#</a></h2>
<p><a href="https://xargin.com/autodumper-for-go/">无人值守的自动 dump(一)</a></p>
<p><a href="https://xargin.com/autodumper-for-go-ii/">无人值守的自动 dump(二)</a></p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="/tags/go/">Go</a></li>
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2021 <a href="/">Forz Blog</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://git.io/hugopapermod" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)">
    <button class="top-link" id="top-link" type="button" accesskey="g">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
            <path d="M12 6H0l6-6z" />
        </svg>
    </button>
</a>

<script>
    let menu = document.getElementById('menu')
    menu.scrollLeft = localStorage.getItem("menu-scroll-position");
    menu.onscroll = function () {
        localStorage.setItem("menu-scroll-position", menu.scrollLeft);
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
